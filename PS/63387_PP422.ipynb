{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions {-}\n",
    "\n",
    "1. Download the provided jupyter notebook file to your computer.\n",
    "2. Write all your answers and code into this notebook file.\n",
    "3. When your work is completed, export your notebook to an HTML file.\n",
    "4. Submit your HTML file and a copy of the notebook to the assignment page on Moodle.\n",
    "\n",
    "__Please ensure you do not save your name as part of your file submission. Also, aim to suppress warning or error messages that may show information about your file path directory which could reveal your identity.__\n",
    "\n",
    "\n",
    "__Please cite any use of AI and include the prompts you provided at the end of the document. The class policy allows for AI to assist in coding, but all written responses should be developed on your own.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Material on the Statistical Techniques {-}\n",
    "\n",
    "This problem set will focus primarily on the LASSO and logistic regressions as new tools for prediction, but it will also draw upon concepts of MSE and prediction error within the testing and training samples. You will also be asked to calculate measures of precision and recall which are introduced in the case study and in lecture this / next week.\n",
    "\n",
    "For a theoretical description of how the LASSO alters traditional regression approaches you should consult Chapter 6, section 6.2.2 of the course textbook (Introduction to Statistical Learning).\n",
    "\n",
    "Another treatment of the LASSO and ridge regressions is provided in the course reading from Géron, Aurélien - Hands-on Machine Learning. Chapter 4 of this text contains a subsection on \"Regularized Linear Models.\" You may find it helpful to read this brief subsection.\n",
    "\n",
    "Other readings from these next weeks are strictly background and show either additional theoretical derivations behind these concepts or applications of these penalized regressions in a public policy context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Introduction to the Case {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan for this case study is to have you learn and apply machine learning tools to make predictions in this problem set which will be due on __Tuesday December 2__. During our regular classes that week we will have a debrief session on this case study to discuss your results and think about some of the broader policy uses of prediction. Please have available a copy of your answers to these questions for this in class discussion.\n",
    "\n",
    "You will do the empirical work related to the Occupational Safety and Health Administration (OSHA) case. To do this, you have been given an OSHA data set on injuries and inspections in work establishments. The goal is to help OSHA improve the way it selects establishments to be inspected. They are under increasing pressure because some policymakers are arguing that OSHA inspections frequently represent an unnecessary cost to businesses. In this problem set, you will be asked to use various algorithms designed to predict a key outcome variable that OSHA could take into account in deciding which establishments to select for inspections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-A {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the provided case study \"Improving Worker Safety in the Era of Machine Learning” (HBS Case #N9-618-09). This case study is available via the [reading list](https://moodle.lse.ac.uk/mod/lti/view.php?id=1809514) on the course Moodle page under the Autumn Term: Week 8 Section.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-B {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case study outlines 4 potential approaches OSHA could select regarding how to identify workplaces to visit. After reading the case study, summarise the key advantages and disadvantages of each of the four targeting approaches compared to OSHA’s current approach, which amounts to selecting randomly from the list of sites with high historical injury rates. [1-2 paragraphs.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your summary here:_\n",
    "\n",
    "Each of the four OSHA site selection approaches has distinct strengths and limitations. The first approach is unique in relying on local knowledge and networks, enabling access to information that might otherwise remain unavailable or undisclosed. However, it is entirely discretionary, lacking standardized criteria for site selection. The third approach enables predictive analysis, though it remains vulnerable to the inherent flaws and biases of the forecasting model employed. The fourth approach combines historical data with predictive modeling, potentially mitigating the limitations of either method used independently, yet it still inherits weaknesses from both and introduces an element of randomness without clear justification for this design choice.\n",
    "\n",
    "The second approach bears similarity to the current random selection process in that both rely on historical data and provide some degree of certainty regarding site risk levels. However, both suffer from dependence on outdated information, and their scope remains constrained by budget limitations. A key distinction exists: while the second method systematically selects locations with the highest historical risk indicators, the current method introduces randomization into the selection process, potentially reducing bias but also reducing targeting efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Data Description and Focus {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided `osha.csv` dataset contains annual observations for a sample of establishments that were in OSHA’s target list of potential sites to inspect through the Site-Specific Targeting (SST) program in the period 2001-2010. These tend to be establishments that are in higher-risk industries that merit OSHA’s close attention. Because of resource constraints, OSHA cannot inspect all sites on such a list. At the moment, the process that OSHA uses to select from this list is akin to a simple random selection. Your job is to see if you can use prediction models to improve on the procedure that OSHA uses.\n",
    "\n",
    "__NOTE__: The case study prompt refers to an example with 6314 observations. I have provided you with a smaller random subset of this data set, so your descriptive statistics will not perfectly match those included in Exhibit 2a of the case appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outcomes__\n",
    "\n",
    "OSHA wants to predict two outcomes:\n",
    "\n",
    "* `injury_rate`: a continuous variable, measured as a “workplace’s annual number of injuries that prompted at least one day away from work (DAFW) per 100 full time equivalent (FTE) employees”\n",
    "* `high_injury_rate`: a binary variable, which is 1 if `injury_rate` is larger than 3 and 0 otherwise.\n",
    "\n",
    "__Predictors__\n",
    "\n",
    "All variables are described in the case (data appendix). Each observation in the data set is a workplace at risk for Site-Specific Targeting (SST) inspection. Some variables represent outcomes in the prediction year, some represent characteristics that are available before the prediction year, and some represent characteristics that are fixed over time (industry, region of the country, etc.).\n",
    "\n",
    "__Predictive Models__\n",
    "\n",
    "I will ask you to evaluate at least three models:\n",
    "\n",
    "1. A simple Ordinary Least Squares (OLS) regression considering a small subset of predictors (referred to here as the `short regression`)\n",
    "2. A \"kitchen-sink\", exhaustive OLS regression which considers all the predictors available (referred to here as the `long regression`)\n",
    "3. A `LASSO regression` which also considers all the predictors available but runs a penalized regression\n",
    "\n",
    "In later portions of the problem set, you will also examine the logistic regression equivalent of the above approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-A: Examining the Data and Outcome Variables {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning your analysis, briefly examine the structure and format of the data set.\n",
    "\n",
    "There are too many individual variables to examine in detail, but you should at least examine and describe the key outcome variables identified above. Briefly summarise the data (1-2 paragraphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osha = pd.read_csv('(...).W8-9 osha_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   injury_rate  high_injury_rate  injuries  sst_year  num_yrs_prev_on_sst  \\\n",
      "0     3.473055                 1        11      2005            -0.205447   \n",
      "1     4.882524                 1         5      2003            -0.821400   \n",
      "2     5.110077                 1         6      2004            -0.821400   \n",
      "3     3.028965                 1         7      2004            -0.821400   \n",
      "4     3.740482                 1         3      2006            -0.821400   \n",
      "5     4.642092                 1         6      2005             1.026457   \n",
      "6     2.582741                 0         1      2007            -0.205447   \n",
      "7     1.389168                 0         1      2006             0.410505   \n",
      "8     4.922267                 1        41      2008             2.258361   \n",
      "9     3.339488                 1         5      2006            -0.205447   \n",
      "\n",
      "   sic_sector_11  sic_sector_21  sic_sector_31  sic_sector_42  sic_sector_44  \\\n",
      "0              0              0              0              0              0   \n",
      "1              0              0              0              1              0   \n",
      "2              0              0              1              0              0   \n",
      "3              0              0              0              0              1   \n",
      "4              0              0              1              0              0   \n",
      "5              0              0              0              1              0   \n",
      "6              0              0              1              0              0   \n",
      "7              0              0              1              0              0   \n",
      "8              0              0              0              0              0   \n",
      "9              1              0              0              0              0   \n",
      "\n",
      "   ...  l2_dafw_has_tmin3_odi  l2_ctransfer_has_tmin3_odi  \\\n",
      "0  ...               0.085173                   -0.032192   \n",
      "1  ...              -0.945378                   -0.848700   \n",
      "2  ...              -0.945378                   -0.848700   \n",
      "3  ...              -0.945378                   -0.848700   \n",
      "4  ...              -0.945378                   -0.848700   \n",
      "5  ...              -0.026806                    0.871523   \n",
      "6  ...              -0.134304                   -0.658836   \n",
      "7  ...              -0.370716                    0.227478   \n",
      "8  ...               0.739057                   -0.651546   \n",
      "9  ...              -0.945378                   -0.848700   \n",
      "\n",
      "   l2_cother_has_tmin3_odi  l2_ln_count_dafw_has_tmin1_odi  \\\n",
      "0                 0.267368                        0.873741   \n",
      "1                -0.722730                        0.429721   \n",
      "2                -0.722730                        0.177163   \n",
      "3                -0.722730                        0.943075   \n",
      "4                -0.722730                        0.177163   \n",
      "5                -0.722730                        0.022249   \n",
      "6                -0.541836                       -1.778378   \n",
      "7                -0.722730                       -0.674328   \n",
      "8                -0.323570                        2.416670   \n",
      "9                -0.722730                        0.429721   \n",
      "\n",
      "   l2_dafw_has_tmin1_odi  l2_ctransfer_has_tmin1_odi  l2_cother_has_tmin1_odi  \\\n",
      "0              -0.206584                   -0.277735                 0.060788   \n",
      "1               0.826538                   -1.096544                 2.155040   \n",
      "2               0.337565                   -1.096544                 3.124103   \n",
      "3               0.429159                   -1.096544                -0.696684   \n",
      "4               0.385525                   -1.096544                -0.668962   \n",
      "5              -0.323759                    0.628527                -0.899079   \n",
      "6              -1.284956                   -1.096544                -0.899079   \n",
      "7              -0.683628                   -0.017333                -0.899079   \n",
      "8               0.477642                   -0.898834                -0.512106   \n",
      "9               0.416031                   -0.524148                -0.547600   \n",
      "\n",
      "   l2_dafw_emp_q2  l2_dafw_emp_q3  l2_dafw_emp_q4  \n",
      "0       -0.455462       -0.454697        0.977916  \n",
      "1        2.316227       -0.454697       -0.426246  \n",
      "2       -0.455462       -0.454697       -0.426246  \n",
      "3       -0.455462       -0.454697        1.805726  \n",
      "4        1.737323       -0.454697       -0.426246  \n",
      "5       -0.455462        0.784932       -0.426246  \n",
      "6        0.658613       -0.454697       -0.426246  \n",
      "7       -0.455462       -0.454697       -0.426246  \n",
      "8       -0.455462       -0.454697        1.868856  \n",
      "9       -0.455462        1.739019       -0.426246  \n",
      "\n",
      "[10 rows x 183 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2149 entries, 0 to 2148\n",
      "Columns: 183 entries, injury_rate to l2_dafw_emp_q4\n",
      "dtypes: float64(140), int64(43)\n",
      "memory usage: 3.0 MB\n",
      "None\n",
      "Index(['injury_rate', 'high_injury_rate', 'injuries', 'sst_year',\n",
      "       'num_yrs_prev_on_sst', 'sic_sector_11', 'sic_sector_21',\n",
      "       'sic_sector_31', 'sic_sector_42', 'sic_sector_44',\n",
      "       ...\n",
      "       'l2_dafw_has_tmin3_odi', 'l2_ctransfer_has_tmin3_odi',\n",
      "       'l2_cother_has_tmin3_odi', 'l2_ln_count_dafw_has_tmin1_odi',\n",
      "       'l2_dafw_has_tmin1_odi', 'l2_ctransfer_has_tmin1_odi',\n",
      "       'l2_cother_has_tmin1_odi', 'l2_dafw_emp_q2', 'l2_dafw_emp_q3',\n",
      "       'l2_dafw_emp_q4'],\n",
      "      dtype='object', length=183)\n",
      "count    2149.000000\n",
      "mean        3.398984\n",
      "std         3.278200\n",
      "min         0.000000\n",
      "25%         1.067976\n",
      "50%         2.532657\n",
      "75%         4.817144\n",
      "max        16.623816\n",
      "Name: injury_rate, dtype: float64\n",
      "count    2149.000000\n",
      "mean        0.436947\n",
      "std         0.496124\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: high_injury_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Your exploratory analysis here:\n",
    "\n",
    "print(osha.head(10))\n",
    "print(osha.info())\n",
    "print(osha.columns)\n",
    "print(osha.injury_rate.describe())\n",
    "print(osha.high_injury_rate.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Data summary:_\n",
    "\n",
    "The OSHA dataset contains 2,149 observations across 183 variables. The majority of variables are continuous (140 float columns), with 43 integer columns. Key variables include `injury_rate` (mean: 3.40, range: 0.00–16.62) and `high_injury_rate`, a binary indicator where approximately 44% of establishments are classified as high-risk (value = 1). The dataset also includes temporal information (`sst_year`), industry classification (`sic_sector_*`), and various lagged injury metrics (prefixed with `l2_`), in accordance with the fact that the data tracks workplace safety outcomes over time, and collects historical injury patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Preprocessing the Data and Creating Initial Models {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been pre-processed in the following ways to make things easier to work with:\n",
    "\n",
    "1. Categorical variables have been transformed into multiple dummy variables\n",
    "2. Non-binary variables have been re-scaled so that each of them has a mean of 0 and a standard deviation of 1.[^1]\n",
    "\n",
    "__NOTE__: For purposes of this assignment, there is no need to standardize the dummy variables further (although we will introduce techniques for this in the WT).\n",
    " \n",
    "[^1]: This \"standardizing\" process helps make coefficients easier to compare across variables and will be necessary for a penalized regression like the LASSO to correctly penalize estimates irrespective of the unit of measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-A: Formula for the Short Regression {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data appendix of the case study describes the variables that should be included in the short regression (in the column \"Included in simple model\" of the Data Appendix). A defensible choice for the short OLS is to start from indicators that the site has gone through inspections or has received some complaints in the past.\n",
    "\n",
    "We can create a formula object to run with our regressions with the following code that includes all of the variables identified for inclusion in this regression.\n",
    "\n",
    "```python\n",
    "f_short_c = 'injury_rate ~ has_tmin1_odi + any_insp_prior + \\\n",
    "  any_complaint_tmin13 + num_nonfat_comp_insp_cy_tc99mm1 + \\\n",
    "  initial_pen_cy_mzmm1 + ln_initial_pen_cy_mzmm1 + \\\n",
    "  dafw_analysis_rec_tc99mm1'\n",
    "```\n",
    "\n",
    "In this code `f_short_c` will be a string representing our regression formula, where it is named for the \"short\" regression and will be used to predict the continuous outcome measure `injury_rate`. This entire string `f_short_c` can be passed as the argument in a regression using the formula notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the regressions formula\n",
    "f_short_c = 'injury_rate ~ has_tmin1_odi + any_insp_prior + \\\n",
    "  any_complaint_tmin13 + num_nonfat_comp_insp_cy_tc99mm1 + \\\n",
    "  initial_pen_cy_mzmm1 + ln_initial_pen_cy_mzmm1 + \\\n",
    "  dafw_analysis_rec_tc99mm1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could save the desired columns as a matrix. Fitting models with this type of matrix is common in the machine learning literature and it can also be used using the `statsmodels.api` syntax. For your convenience, the below block of code saves these variables in a list should you wish to create this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_vars = ['has_tmin1_odi', 'any_insp_prior', 'any_complaint_tmin13', 'num_nonfat_comp_insp_cy_tc99mm1',\n",
    "                        'initial_pen_cy_mzmm1', 'ln_initial_pen_cy_mzmm1', 'dafw_analysis_rec_tc99mm1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these provided variables and whichever technique you prefer, fit a simple OLS regression to the full data set using only the short model subset of variables (be sure your model also includes the intercept term). Doing this now will confirm your regression setup is correct before moving on to other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            injury_rate   R-squared:                       0.317\n",
      "Model:                            OLS   Adj. R-squared:                  0.314\n",
      "Method:                 Least Squares   F-statistic:                     141.7\n",
      "Date:                Mon, 01 Dec 2025   Prob (F-statistic):          6.95e-172\n",
      "Time:                        22:03:11   Log-Likelihood:                -5191.3\n",
      "No. Observations:                2149   AIC:                         1.040e+04\n",
      "Df Residuals:                    2141   BIC:                         1.044e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           3.2530      0.213     15.277      0.000       2.835       3.671\n",
      "has_tmin1_odi                       0.1546      0.218      0.710      0.478      -0.272       0.582\n",
      "any_insp_prior                      0.0636      0.131      0.484      0.629      -0.194       0.321\n",
      "any_complaint_tmin13               -0.0346      0.204     -0.169      0.866      -0.435       0.366\n",
      "num_nonfat_comp_insp_cy_tc99mm1    -0.0917      0.062     -1.470      0.142      -0.214       0.031\n",
      "initial_pen_cy_mzmm1                0.0548      0.075      0.734      0.463      -0.091       0.201\n",
      "ln_initial_pen_cy_mzmm1             0.0945      0.083      1.135      0.257      -0.069       0.258\n",
      "dafw_analysis_rec_tc99mm1           1.8391      0.059     31.062      0.000       1.723       1.955\n",
      "==============================================================================\n",
      "Omnibus:                      422.888   Durbin-Watson:                   2.032\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1060.476\n",
      "Skew:                           1.064   Prob(JB):                    5.25e-231\n",
      "Kurtosis:                       5.704   Cond. No.                         7.84\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit the short regression model to the full data\n",
    "\n",
    "model = smf.ols(f_short_c, data=osha).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-B: Formula for the Long Regression {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kitchen-sink, or \"long\" regression should include all the available variables in the data __EXCEPT__ for the following: `sst_year` (the year), `estab_id_duns` (the workplace identifier), `injuries`, `injury_rate`, and `high_injury_rate` (the three outcome measures). \n",
    "\n",
    "Estimate this \"long\" regression model on the full data set, again predicting the outcome `injury_rate`, but including all other variables except those noted above.\n",
    "\n",
    "This formula will include many terms (178 features), and would be too long to type out by hand which would be prone to error.\n",
    "\n",
    "Hint 1: using matrix notation for fitting the model avoids the need to create your own formula if you can drop the excluded columns.\n",
    "\n",
    "Hint 2: if you want to create a regression formula, you can use the [str.join()](https://www.w3schools.com/python/ref_string_join.asp) method to reliably and quickly write the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            injury_rate   R-squared:                       0.446\n",
      "Model:                            OLS   Adj. R-squared:                  0.396\n",
      "Method:                 Least Squares   F-statistic:                     8.896\n",
      "Date:                Mon, 01 Dec 2025   Prob (F-statistic):          4.41e-153\n",
      "Time:                        22:03:14   Log-Likelihood:                -4966.5\n",
      "No. Observations:                2149   AIC:                         1.029e+04\n",
      "Df Residuals:                    1970   BIC:                         1.131e+04\n",
      "Df Model:                         178                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                            0.3145      1.210      0.260      0.795      -2.059       2.688\n",
      "num_yrs_prev_on_sst                  0.1890      0.084      2.249      0.025       0.024       0.354\n",
      "sic_sector_11                        0.6022      0.980      0.615      0.539      -1.319       2.523\n",
      "sic_sector_21                       10.6350      3.422      3.108      0.002       3.924      17.347\n",
      "sic_sector_31                        0.9472      0.775      1.222      0.222      -0.572       2.467\n",
      "sic_sector_42                        0.7660      0.795      0.963      0.336      -0.794       2.326\n",
      "sic_sector_44                        0.3385      0.807      0.420      0.675      -1.243       1.920\n",
      "sic_sector_48                        1.0798      0.791      1.365      0.172      -0.472       2.631\n",
      "sic_sector_805                       1.3770      0.805      1.710      0.087      -0.202       2.956\n",
      "wp_days_2008                         0.0498      0.081      0.612      0.540      -0.110       0.209\n",
      "has_tmin1_odi                        1.7855      0.726      2.458      0.014       0.361       3.210\n",
      "has_tmin3_odi                        0.7507      0.547      1.373      0.170      -0.321       1.823\n",
      "any_rep_will_viol_4yr                0.2304      0.439      0.525      0.600      -0.631       1.092\n",
      "any_complaint_tmin13                 0.3589      0.243      1.478      0.140      -0.117       0.835\n",
      "any_fatcat_tmin13                    0.2305      0.877      0.263      0.793      -1.489       1.950\n",
      "any_insp_prior                      -0.0177      0.156     -0.114      0.910      -0.323       0.288\n",
      "avg_hours_analysis_tc99mm1          -0.9476      2.014     -0.470      0.638      -4.898       3.002\n",
      "avg_hours_analysis_tc99mm2          -1.6616      2.485     -0.669      0.504      -6.536       3.213\n",
      "avg_hours_analysis_tc99mm3           0.4520      1.961      0.231      0.818      -3.393       4.297\n",
      "avg_hours_analysis_tc99_2mm1         0.0313      3.060      0.010      0.992      -5.970       6.032\n",
      "avg_hours_analysis_tc99_2mm2         2.5351      3.627      0.699      0.485      -4.578       9.648\n",
      "avg_hours_analysis_tc99_2mm3        -0.1792      2.906     -0.062      0.951      -5.878       5.519\n",
      "avg_hours_analysis_tc99_3mm1         0.1604      1.733      0.093      0.926      -3.239       3.559\n",
      "avg_hours_analysis_tc99_3mm2        -1.4054      1.963     -0.716      0.474      -5.255       2.444\n",
      "avg_hours_analysis_tc99_3mm3        -0.1345      1.591     -0.085      0.933      -3.254       2.985\n",
      "ln_avg_hours_analysismm1             0.6859      0.658      1.042      0.297      -0.604       1.976\n",
      "ln_avg_hours_analysismm2            -0.1191      0.912     -0.131      0.896      -1.908       1.670\n",
      "ln_avg_hours_analysismm3            -0.1079      0.688     -0.157      0.875      -1.457       1.241\n",
      "count_dafw_analysis_tc99mm1          5.0301      3.078      1.634      0.102      -1.006      11.066\n",
      "count_dafw_analysis_tc99mm2         -2.6100      3.459     -0.755      0.451      -9.394       4.174\n",
      "count_dafw_analysis_tc99mm3         -0.2049      3.097     -0.066      0.947      -6.279       5.869\n",
      "count_dafw_analysis_tc99_2mm1       -5.5203      3.669     -1.504      0.133     -12.716       1.676\n",
      "count_dafw_analysis_tc99_2mm2        4.5994      4.254      1.081      0.280      -3.743      12.942\n",
      "count_dafw_analysis_tc99_2mm3        0.3642      3.845      0.095      0.925      -7.176       7.904\n",
      "count_dafw_analysis_tc99_3mm1        2.7940      1.792      1.559      0.119      -0.720       6.308\n",
      "count_dafw_analysis_tc99_3mm2       -2.6342      2.073     -1.271      0.204      -6.700       1.432\n",
      "count_dafw_analysis_tc99_3mm3       -0.2698      1.890     -0.143      0.887      -3.977       3.437\n",
      "ln_count_dafw_analysismm1            0.9504      1.555      0.611      0.541      -2.099       4.000\n",
      "ln_count_dafw_analysismm2            2.8590      2.118      1.350      0.177      -1.296       7.014\n",
      "ln_count_dafw_analysismm3            0.2814      1.792      0.157      0.875      -3.233       3.796\n",
      "ln_count_dafw_analysis_2mm1         -4.5440      3.732     -1.218      0.224     -11.863       2.775\n",
      "ln_count_dafw_analysis_2mm2         -0.9061      4.747     -0.191      0.849     -10.217       8.405\n",
      "ln_count_dafw_analysis_2mm3         -0.2213      4.166     -0.053      0.958      -8.391       7.948\n",
      "ln_count_dafw_analysis_3mm1          2.0041      1.873      1.070      0.285      -1.670       5.678\n",
      "ln_count_dafw_analysis_3mm2          0.6099      2.554      0.239      0.811      -4.398       5.618\n",
      "ln_count_dafw_analysis_3mm3         -0.0520      2.202     -0.024      0.981      -4.371       4.267\n",
      "ln_dafw_analysis_recmm1             -0.9209      0.751     -1.226      0.220      -2.394       0.552\n",
      "ln_dafw_analysis_recmm2             -1.0794      0.919     -1.174      0.240      -2.882       0.723\n",
      "ln_dafw_analysis_recmm3             -0.4322      0.803     -0.538      0.591      -2.008       1.143\n",
      "dafw_analysis_rec_tc99mm1            2.2630      0.722      3.136      0.002       0.848       3.678\n",
      "dafw_analysis_rec_tc99mm2            1.2065      0.883      1.367      0.172      -0.524       2.937\n",
      "dafw_analysis_rec_tc99mm3            1.1743      0.736      1.596      0.111      -0.269       2.617\n",
      "dafw_analysis_rec_tc99_2mm1         -0.7303      0.381     -1.917      0.055      -1.477       0.017\n",
      "dafw_analysis_rec_tc99_2mm2         -0.2535      0.438     -0.579      0.563      -1.113       0.606\n",
      "dafw_analysis_rec_tc99_2mm3         -0.5606      0.398     -1.409      0.159      -1.341       0.220\n",
      "cother_analysis_rec_tc99mm1          0.4146      0.159      2.606      0.009       0.103       0.727\n",
      "cother_analysis_rec_tc99mm2          0.0636      0.269      0.237      0.813      -0.463       0.591\n",
      "cother_analysis_rec_tc99mm3         -0.2159      0.171     -1.259      0.208      -0.552       0.120\n",
      "cother_analysis_rec_tc99_2mm1       -0.2548      0.157     -1.626      0.104      -0.562       0.053\n",
      "cother_analysis_rec_tc99_2mm2       -0.1313      0.176     -0.746      0.456      -0.477       0.214\n",
      "cother_analysis_rec_tc99_2mm3        0.3085      0.170      1.810      0.070      -0.026       0.643\n",
      "ctransfer_analysis_rec_tc99mm1      -0.5066      0.186     -2.721      0.007      -0.872      -0.141\n",
      "ctransfer_analysis_rec_tc99mm2       0.2216      0.333      0.666      0.505      -0.431       0.874\n",
      "ctransfer_analysis_rec_tc99mm3       0.2330      0.189      1.233      0.218      -0.138       0.604\n",
      "ctransfer_analysis_rec_tc99_2mm1     0.4335      0.170      2.552      0.011       0.100       0.767\n",
      "ctransfer_analysis_rec_tc99_2mm2    -0.0122      0.201     -0.061      0.951      -0.406       0.381\n",
      "ctransfer_analysis_rec_tc99_2mm3    -0.0813      0.175     -0.465      0.642      -0.424       0.261\n",
      "any_deathsmm1                       -0.2099      0.108     -1.942      0.052      -0.422       0.002\n",
      "any_deathsmm2                        0.1427      0.861      0.166      0.868      -1.546       1.831\n",
      "any_strikesmm1                      -0.0145      0.070     -0.207      0.836      -0.152       0.123\n",
      "any_strikesmm2                      -0.1304      1.220     -0.107      0.915      -2.523       2.262\n",
      "any_shutdownmm1                     -0.0488      0.063     -0.769      0.442      -0.173       0.076\n",
      "any_shutdownmm2                      0.3770      0.226      1.669      0.095      -0.066       0.820\n",
      "any_seasonalmm1                     -0.1150      0.067     -1.722      0.085      -0.246       0.016\n",
      "any_seasonalmm2                      0.8744      0.338      2.583      0.010       0.211       1.538\n",
      "any_disastermm1                      0.0645      0.056      1.145      0.252      -0.046       0.175\n",
      "any_disastermm2                     -0.0476      0.732     -0.065      0.948      -1.482       1.387\n",
      "any_long_schmm1                      0.0138      0.059      0.235      0.814      -0.102       0.129\n",
      "any_long_schmm2                      0.3744      0.362      1.034      0.301      -0.336       1.085\n",
      "any_illnessmm1                      -0.0353      0.065     -0.540      0.589      -0.163       0.093\n",
      "any_illnessmm2                       0.1407      0.142      0.989      0.323      -0.138       0.420\n",
      "ln_daway_analysismm2                -0.0482      0.101     -0.476      0.634      -0.247       0.151\n",
      "ln_dtransfer_analysismm2            -0.1567      0.100     -1.562      0.118      -0.353       0.040\n",
      "paydexmin_netsmm1                   -0.0250      0.082     -0.305      0.761      -0.186       0.136\n",
      "paydexmin_netsmt1                   -0.3183      0.338     -0.941      0.347      -0.982       0.345\n",
      "paydexmin_netsmm2                    0.0847      0.082      1.033      0.302      -0.076       0.246\n",
      "paydexmin_netsmt2                    0.1384      0.330      0.419      0.675      -0.510       0.786\n",
      "ln_sales_netsmm1                     0.0806      0.308      0.262      0.794      -0.524       0.685\n",
      "ln_sales_netsmm2                     0.0982      0.309      0.318      0.751      -0.508       0.704\n",
      "ln_sales_netsmt2                     0.3388      0.585      0.580      0.562      -0.808       1.485\n",
      "ln_emp_netsmm1                      -0.2029      0.259     -0.784      0.433      -0.711       0.305\n",
      "ln_emp_netsmm2                       0.0005      0.272      0.002      0.999      -0.533       0.534\n",
      "ln_emp_netsmm3                       0.0122      0.123      0.100      0.921      -0.229       0.253\n",
      "avg_viol_sic3mm1                    -0.1398      0.141     -0.994      0.320      -0.416       0.136\n",
      "avg_viol_sic3mm2                     0.1626      0.142      1.148      0.251      -0.115       0.440\n",
      "avg_viol_sic3mm3                    -0.1948      0.149     -1.308      0.191      -0.487       0.097\n",
      "avg_viol_stmm1                      -0.2893      0.266     -1.088      0.277      -0.811       0.232\n",
      "avg_viol_stmm2                       0.6163      0.371      1.662      0.097      -0.111       1.343\n",
      "avg_viol_stmm3                      -0.2785      0.307     -0.907      0.365      -0.881       0.324\n",
      "avg_pen_sic3mm1                      0.1895      0.123      1.535      0.125      -0.053       0.432\n",
      "avg_pen_sic3mm2                      0.0600      0.121      0.496      0.620      -0.177       0.297\n",
      "avg_pen_sic3mm3                     -0.0291      0.171     -0.170      0.865      -0.364       0.306\n",
      "avg_pen_stmm1                       -0.1957      0.189     -1.036      0.300      -0.566       0.175\n",
      "avg_pen_stmm2                       -0.0485      0.213     -0.228      0.820      -0.466       0.369\n",
      "avg_pen_stmm3                       -0.1356      0.216     -0.628      0.530      -0.559       0.288\n",
      "avg_gravity_sic3mm1                 -0.0985      0.125     -0.786      0.432      -0.344       0.147\n",
      "avg_gravity_sic3mm2                 -0.0812      0.131     -0.621      0.535      -0.338       0.175\n",
      "avg_gravity_sic3mm3                  0.1950      0.137      1.420      0.156      -0.074       0.464\n",
      "avg_gravity_stmm1                    0.5057      0.294      1.720      0.086      -0.071       1.082\n",
      "avg_gravity_stmm2                   -0.5720      0.432     -1.323      0.186      -1.420       0.276\n",
      "avg_gravity_stmm3                    0.3778      0.312      1.212      0.225      -0.233       0.989\n",
      "loom_dafw_rec_tc99_s4yrmm1           0.2108      0.178      1.186      0.236      -0.138       0.559\n",
      "loom_dafw_rec_tc99_s4yrmm2           0.2337      0.191      1.226      0.220      -0.140       0.608\n",
      "loom_dafw_rec_tc99_styrmm1          -0.1366      0.324     -0.421      0.674      -0.772       0.499\n",
      "loom_dafw_rec_tc99_styrmm2           0.7049      0.347      2.033      0.042       0.025       1.385\n",
      "loom_ctransfer_rec_tc99_s4yrmm1      0.0309      0.131      0.237      0.813      -0.225       0.287\n",
      "loom_ctransfer_rec_tc99_s4yrmm2     -0.1425      0.128     -1.112      0.266      -0.394       0.109\n",
      "loom_ctransfer_rec_tc99_styrmm1      0.3043      0.301      1.010      0.313      -0.287       0.895\n",
      "loom_ctransfer_rec_tc99_styrmm2     -0.4674      0.307     -1.522      0.128      -1.069       0.135\n",
      "loom_cother_rec_tc99_s4yrmm1        -0.2547      0.200     -1.274      0.203      -0.647       0.137\n",
      "loom_cother_rec_tc99_s4yrmm2        -0.1191      0.207     -0.576      0.564      -0.524       0.286\n",
      "loom_cother_rec_tc99_styrmm1         0.5346      0.390      1.372      0.170      -0.229       1.299\n",
      "loom_cother_rec_tc99_styrmm2        -0.5950      0.403     -1.478      0.140      -1.385       0.195\n",
      "sd_dafw_rec_tc99_s3yrmm1            -0.2959      0.163     -1.818      0.069      -0.615       0.023\n",
      "sd_dafw_rec_tc99_s3yrmm2            -0.0195      0.164     -0.119      0.906      -0.341       0.302\n",
      "sd_dafw_rec_tc99_styrmm1             0.1337      0.151      0.886      0.376      -0.162       0.430\n",
      "sd_dafw_rec_tc99_styrmm2            -0.4042      0.203     -1.992      0.047      -0.802      -0.006\n",
      "sd_ctransfer_rec_tc99_s3yrmm1        0.1293      0.102      1.264      0.206      -0.071       0.330\n",
      "sd_ctransfer_rec_tc99_s3yrmm2        0.1324      0.103      1.291      0.197      -0.069       0.334\n",
      "sd_ctransfer_rec_tc99_styrmm1       -0.1107      0.224     -0.494      0.621      -0.550       0.328\n",
      "sd_ctransfer_rec_tc99_styrmm2        0.3228      0.221      1.462      0.144      -0.110       0.756\n",
      "sd_cother_rec_tc99_s3yrmm1           0.2082      0.173      1.201      0.230      -0.132       0.548\n",
      "sd_cother_rec_tc99_s3yrmm2           0.0110      0.175      0.063      0.950      -0.332       0.354\n",
      "sd_cother_rec_tc99_styrmm1           0.0848      0.263      0.323      0.747      -0.431       0.600\n",
      "sd_cother_rec_tc99_styrmm2          -0.1226      0.272     -0.452      0.652      -0.655       0.410\n",
      "gravity_cy_mzmm1                     0.2361      0.102      2.321      0.020       0.037       0.436\n",
      "gravity_cy_mzmm2                    -0.0717      0.124     -0.580      0.562      -0.314       0.171\n",
      "gravity_cy_mzmm3                    -0.0552      0.086     -0.643      0.521      -0.224       0.113\n",
      "ln_initial_pen_cy_mzmm1             -0.2182      0.124     -1.763      0.078      -0.461       0.025\n",
      "ln_initial_pen_cy_mzmm2             -0.0716      0.122     -0.587      0.558      -0.311       0.168\n",
      "ln_initial_pen_cy_mzmm3             -0.1498      0.118     -1.271      0.204      -0.381       0.081\n",
      "initial_pen_cy_mzmm1                 0.5312      0.303      1.753      0.080      -0.063       1.125\n",
      "initial_pen_cy_mzmm2                -0.0937      0.212     -0.443      0.658      -0.509       0.321\n",
      "initial_pen_cy_mzmm3                -0.0305      0.251     -0.122      0.903      -0.523       0.462\n",
      "initial_pen_cy_mz_2mm1              -0.9035      0.350     -2.581      0.010      -1.590      -0.217\n",
      "initial_pen_cy_mz_2mm2               0.0558      0.126      0.443      0.658      -0.192       0.303\n",
      "initial_pen_cy_mz_2mm3               0.0375      0.203      0.184      0.854      -0.362       0.436\n",
      "public_netsmm1                      -0.1717      0.181     -0.951      0.342      -0.526       0.182\n",
      "standalone_netsmm1                  -0.4457      0.180     -2.480      0.013      -0.798      -0.093\n",
      "headquarters_netsmm1                -0.4216      0.219     -1.929      0.054      -0.850       0.007\n",
      "foreign_owned_netsmm1               -0.1403      0.237     -0.592      0.554      -0.605       0.324\n",
      "estab_age_netsmm1                    0.0557      0.210      0.266      0.791      -0.355       0.467\n",
      "estab_age2_netsmm1                   0.0464      0.192      0.242      0.809      -0.330       0.423\n",
      "govt_contractor_netsmm1              0.1362      0.207      0.659      0.510      -0.269       0.541\n",
      "exporter_netsmm1                    -0.4503      0.362     -1.245      0.213      -1.159       0.259\n",
      "importer_netsmm1                     0.1153      0.184      0.625      0.532      -0.246       0.477\n",
      "exp_imp_netsmm1                      0.0275      0.321      0.086      0.932      -0.602       0.657\n",
      "region_dum1                          0.1512      0.692      0.218      0.827      -1.206       1.509\n",
      "region_dum2                          0.2866      0.733      0.391      0.696      -1.151       1.725\n",
      "region_dum3                          0.2477      0.641      0.387      0.699      -1.009       1.504\n",
      "region_dum4                          0.0708      0.680      0.104      0.917      -1.263       1.404\n",
      "region_dum5                          0.0591      0.672      0.088      0.930      -1.260       1.378\n",
      "region_dum6                         -0.1025      0.673     -0.152      0.879      -1.423       1.218\n",
      "region_dum7                          0.2682      0.689      0.389      0.697      -1.083       1.620\n",
      "region_dum8                         -0.0396      0.697     -0.057      0.955      -1.407       1.328\n",
      "num_nonfat_comp_insp_cy_tc99mm1     -0.0158      0.064     -0.248      0.805      -0.141       0.109\n",
      "num_nonfat_comp_insp_cy_tc99mm2      0.0638      0.078      0.821      0.412      -0.089       0.216\n",
      "num_nonfat_comp_insp_cy_tc99mm3      0.1539      0.087      1.767      0.077      -0.017       0.325\n",
      "l2_ln_count_dafw_has_tmin3_odi      -0.3868      0.396     -0.978      0.328      -1.163       0.389\n",
      "l2_dafw_has_tmin3_odi                0.1043      0.280      0.372      0.710      -0.446       0.654\n",
      "l2_ctransfer_has_tmin3_odi          -0.2009      0.159     -1.261      0.208      -0.514       0.112\n",
      "l2_cother_has_tmin3_odi             -0.0507      0.139     -0.364      0.716      -0.324       0.222\n",
      "l2_ln_count_dafw_has_tmin1_odi      -0.4863      0.527     -0.922      0.357      -1.521       0.548\n",
      "l2_dafw_has_tmin1_odi               -0.3930      0.427     -0.921      0.357      -1.230       0.444\n",
      "l2_ctransfer_has_tmin1_odi          -0.1102      0.262     -0.421      0.674      -0.624       0.403\n",
      "l2_cother_has_tmin1_odi              0.0016      0.222      0.007      0.994      -0.434       0.437\n",
      "l2_dafw_emp_q2                       0.0042      0.087      0.048      0.962      -0.167       0.175\n",
      "l2_dafw_emp_q3                       0.0308      0.116      0.265      0.791      -0.197       0.259\n",
      "l2_dafw_emp_q4                      -0.2064      0.164     -1.256      0.209      -0.529       0.116\n",
      "==============================================================================\n",
      "Omnibus:                      342.427   Durbin-Watson:                   2.031\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              801.058\n",
      "Skew:                           0.898   Prob(JB):                    1.13e-174\n",
      "Kurtosis:                       5.391   Cond. No.                         742.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit the long regression model to the full data\n",
    "\n",
    "cols_excluded = ['sst_year', 'estab_id_duns', 'injuries', 'injury_rate', 'high_injury_rate']\n",
    "cols_used = [col for col in osha.columns if col not in cols_excluded]\n",
    "formula = 'injury_rate ~ ' + '+'.join(cols_used)\n",
    "kls_model = smf.ols(formula, data=osha).fit()\n",
    "print(ks_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to report your regression results or examine the coefficients in detail here, but do run the code to confirm there are no errors in this construction of your formulas before moving on to the next portions of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-C: Splitting the Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data 70-30 into training and test data sets respectively. Use the [train_test_split](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) function from `sklearn` and set the random_state argument to `407` to ensure your split matches the solutions. \n",
    "\n",
    "Briefly examine the structure of your training and testing splits. Report how many observations are in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      injury_rate  high_injury_rate  injuries  sst_year  num_yrs_prev_on_sst  \\\n",
      "1716     3.072996                 1         2      2001            -0.821400   \n",
      "1339     7.193075                 1         6      2009            -0.821400   \n",
      "102      1.168811                 0         1      2009             0.410505   \n",
      "867      0.000000                 0         0      2006             0.410505   \n",
      "783      6.068804                 1         5      2005             1.026457   \n",
      "...           ...               ...       ...       ...                  ...   \n",
      "212      0.000000                 0         0      2004            -0.205447   \n",
      "93       1.044817                 0         1      2010             1.026457   \n",
      "975      0.000000                 0         0      2010            -0.821400   \n",
      "248      5.342503                 1         8      2001            -0.821400   \n",
      "1755     0.000000                 0         0      2010            -0.821400   \n",
      "\n",
      "      sic_sector_11  sic_sector_21  sic_sector_31  sic_sector_42  \\\n",
      "1716              0              0              1              0   \n",
      "1339              0              0              0              0   \n",
      "102               0              0              1              0   \n",
      "867               0              0              0              1   \n",
      "783               0              0              1              0   \n",
      "...             ...            ...            ...            ...   \n",
      "212               0              0              1              0   \n",
      "93                0              0              1              0   \n",
      "975               0              0              1              0   \n",
      "248               0              0              0              0   \n",
      "1755              0              0              1              0   \n",
      "\n",
      "      sic_sector_44  ...  l2_dafw_has_tmin3_odi  l2_ctransfer_has_tmin3_odi  \\\n",
      "1716              0  ...               0.164803                   -0.502191   \n",
      "1339              0  ...              -0.945378                   -0.848700   \n",
      "102               0  ...              -0.945378                   -0.848700   \n",
      "867               0  ...               0.956594                   -0.255058   \n",
      "783               0  ...               0.302072                    0.027344   \n",
      "...             ...  ...                    ...                         ...   \n",
      "212               0  ...               0.383988                    1.018442   \n",
      "93                0  ...              -0.751227                    0.787448   \n",
      "975               0  ...              -0.634367                   -0.266265   \n",
      "248               0  ...               0.201007                   -0.081967   \n",
      "1755              0  ...              -0.945378                   -0.848700   \n",
      "\n",
      "      l2_cother_has_tmin3_odi  l2_ln_count_dafw_has_tmin1_odi  \\\n",
      "1716                 0.267686                       -0.385222   \n",
      "1339                -0.722730                       -1.778378   \n",
      "102                 -0.722730                       -0.385222   \n",
      "867                 -0.345666                        0.535603   \n",
      "783                 -0.166291                       -0.160974   \n",
      "...                       ...                             ...   \n",
      "212                  1.204449                        0.429721   \n",
      "93                  -0.203112                       -1.081800   \n",
      "975                 -0.722730                       -1.778378   \n",
      "248                 -0.138322                        0.311355   \n",
      "1755                -0.722730                        0.429721   \n",
      "\n",
      "      l2_dafw_has_tmin1_odi  l2_ctransfer_has_tmin1_odi  \\\n",
      "1716              -0.123260                   -0.749059   \n",
      "1339              -1.284956                   -1.096544   \n",
      "102               -0.460743                   -0.110394   \n",
      "867                0.705273                   -0.501229   \n",
      "783                0.020380                   -0.218031   \n",
      "...                     ...                         ...   \n",
      "212                0.106097                    0.775860   \n",
      "93                -1.081796                    0.544215   \n",
      "975               -1.284956                   -1.096544   \n",
      "248               -0.085375                   -0.327650   \n",
      "1755              -0.048337                   -0.819122   \n",
      "\n",
      "      l2_cother_has_tmin1_odi  l2_dafw_emp_q2  l2_dafw_emp_q3  l2_dafw_emp_q4  \n",
      "1716                 0.061097       -0.455462       -0.454697       -0.426246  \n",
      "1339                -0.899079       -0.455462       -0.454697       -0.426246  \n",
      "102                 -0.672000        0.626455       -0.454697       -0.426246  \n",
      "867                 -0.533527        2.157046       -0.454697       -0.426246  \n",
      "783                 -0.359630       -0.455462       -0.454697       -0.426246  \n",
      "...                       ...             ...             ...             ...  \n",
      "212                  0.969258       -0.455462        1.339306       -0.426246  \n",
      "93                  -0.395327       -0.455462       -0.192688       -0.426246  \n",
      "975                 -0.899079       -0.455462       -0.454697       -0.426246  \n",
      "248                 -0.332514       -0.455462        1.092370       -0.426246  \n",
      "1755                -0.260266       -0.455462        1.140137       -0.426246  \n",
      "\n",
      "[1504 rows x 183 columns]       injury_rate  high_injury_rate  injuries  sst_year  num_yrs_prev_on_sst  \\\n",
      "2135     1.364045                 0         3      2010             1.026457   \n",
      "657      0.284603                 0         1      2010            -0.821400   \n",
      "838      2.048228                 0         3      2007            -0.205447   \n",
      "553      1.752540                 0         2      2008            -0.821400   \n",
      "1110     1.293108                 0         1      2002            -0.205447   \n",
      "...           ...               ...       ...       ...                  ...   \n",
      "1766     4.207822                 1         4      2003             0.410505   \n",
      "2009     0.000000                 0         0      2010             0.410505   \n",
      "237      8.015199                 1        12      2006             0.410505   \n",
      "1039     3.887682                 1        47      2004             1.026457   \n",
      "797      2.880754                 0         4      2005            -0.821400   \n",
      "\n",
      "      sic_sector_11  sic_sector_21  sic_sector_31  sic_sector_42  \\\n",
      "2135              0              0              1              0   \n",
      "657               0              0              1              0   \n",
      "838               0              0              1              0   \n",
      "553               0              0              0              1   \n",
      "1110              0              0              0              0   \n",
      "...             ...            ...            ...            ...   \n",
      "1766              0              0              1              0   \n",
      "2009              0              0              0              0   \n",
      "237               0              0              1              0   \n",
      "1039              0              0              0              0   \n",
      "797               0              0              0              0   \n",
      "\n",
      "      sic_sector_44  ...  l2_dafw_has_tmin3_odi  l2_ctransfer_has_tmin3_odi  \\\n",
      "2135              0  ...              -0.416912                    0.223439   \n",
      "657               0  ...              -0.853320                    0.530487   \n",
      "838               0  ...              -0.498809                    0.823893   \n",
      "553               0  ...              -0.945378                   -0.848700   \n",
      "1110              0  ...               0.268975                   -0.564433   \n",
      "...             ...  ...                    ...                         ...   \n",
      "1766              0  ...               0.475450                   -0.050458   \n",
      "2009              1  ...              -0.416745                    0.141279   \n",
      "237               0  ...              -0.945378                   -0.848700   \n",
      "1039              0  ...               1.370177                   -0.483958   \n",
      "797               0  ...              -0.945378                   -0.848700   \n",
      "\n",
      "      l2_cother_has_tmin3_odi  l2_ln_count_dafw_has_tmin1_odi  \\\n",
      "2135                -0.408426                        0.177163   \n",
      "657                 -0.722730                       -1.081800   \n",
      "838                 -0.125139                       -0.674328   \n",
      "553                 -0.722730                       -0.674328   \n",
      "1110                 0.360620                       -0.160974   \n",
      "...                       ...                             ...   \n",
      "1766                -0.469220                        0.022249   \n",
      "2009                -0.565528                       -0.385222   \n",
      "237                 -0.722730                        0.799266   \n",
      "1039                 1.304414                        2.926926   \n",
      "797                 -0.722730                       -0.160974   \n",
      "\n",
      "      l2_dafw_has_tmin1_odi  l2_ctransfer_has_tmin1_odi  \\\n",
      "2135              -0.731967                   -0.021384   \n",
      "657               -1.188626                    0.286530   \n",
      "838               -0.817665                    0.580763   \n",
      "553               -0.947190                    0.267391   \n",
      "1110              -0.014254                   -0.811476   \n",
      "...                     ...                         ...   \n",
      "1766               0.201803                   -0.296053   \n",
      "2009              -0.731792                   -0.103775   \n",
      "237                0.647668                   -1.096544   \n",
      "1039               1.138048                   -0.730774   \n",
      "797               -0.593943                    1.228773   \n",
      "\n",
      "      l2_cother_has_tmin1_odi  l2_dafw_emp_q2  l2_dafw_emp_q3  l2_dafw_emp_q4  \n",
      "2135                -0.594371       -0.455462       -0.454697        0.293808  \n",
      "657                 -0.899079       -0.455462       -0.454697       -0.300814  \n",
      "838                 -0.319734       -0.455462        0.147956       -0.426246  \n",
      "553                 -0.061558       -0.455462       -0.019089       -0.426246  \n",
      "1110                 0.151193       -0.455462       -0.454697       -0.426246  \n",
      "...                       ...             ...             ...             ...  \n",
      "1766                -0.653309       -0.455462       -0.454697       -0.426246  \n",
      "2009                -0.746677       -0.455462        0.258703       -0.426246  \n",
      "237                 -0.366622       -0.455462        2.037756       -0.426246  \n",
      "1039                 1.066170       -0.455462       -0.454697        2.728779  \n",
      "797                 -0.613508       -0.455462       -0.454697        0.473531  \n",
      "\n",
      "[645 rows x 183 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the data and examine the structure\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "osha_train, osha_test = train_test_split(osha, test_size=.30, train_size=.70, random_state=407)\n",
    "print(osha_train, osha_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1504 observations, 183 features\n",
      "Size of test set: 645 observations, 183 features\n"
     ]
    }
   ],
   "source": [
    "# Structure of splits\n",
    "\n",
    "print(f\"Size of training set: {osha_train.shape[0]} observations, {osha_train.shape[1]} features\")\n",
    "print(f\"Size of test set: {osha_test.shape[0]} observations, {osha_test.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this problem it will be useful to have separate arrays saved containing our outcome variables for the `injury_rate` measure. Create new variables storing these measures from both the training and testing data. You can reference these variables both in your calls to fit models and when calculating measures of model fit like the MSE.\n",
    "\n",
    "1. Save an array of the `injury_rate` in the training sample as `y_c_train`\n",
    "2. Save an array of the `injury_rate` in the testing sample as `y_c_test`\n",
    "\n",
    "Where the letter 'c' in the above variable names refers to this outcome measure being continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the outcome variable from the training / testing data\n",
    "\n",
    "y_c_train = osha_train['injury_rate']\n",
    "y_c_test = osha_test['injury_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-D: Linear Models {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You previously built both the \"short\" and \"long\" linear regression models for the full data set. Now, fit each of these models on the _training data_ you created above. Be sure to save your model objects as we will need to extract predictions and goodness of fit measures from these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              y_c_train   R-squared:                       0.332\n",
      "Model:                            OLS   Adj. R-squared:                  0.329\n",
      "Method:                 Least Squares   F-statistic:                     106.2\n",
      "Date:                Mon, 01 Dec 2025   Prob (F-statistic):          2.37e-126\n",
      "Time:                        22:03:44   Log-Likelihood:                -3606.0\n",
      "No. Observations:                1504   AIC:                             7228.\n",
      "Df Residuals:                    1496   BIC:                             7271.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           3.4365      0.246     13.982      0.000       2.954       3.919\n",
      "has_tmin1_odi                       0.0083      0.252      0.033      0.974      -0.486       0.503\n",
      "any_insp_prior                     -0.0247      0.155     -0.159      0.873      -0.329       0.280\n",
      "any_complaint_tmin13               -0.0305      0.234     -0.130      0.896      -0.490       0.429\n",
      "num_nonfat_comp_insp_cy_tc99mm1    -0.1015      0.071     -1.437      0.151      -0.240       0.037\n",
      "initial_pen_cy_mzmm1                0.0374      0.081      0.464      0.643      -0.121       0.195\n",
      "ln_initial_pen_cy_mzmm1             0.0852      0.097      0.880      0.379      -0.105       0.275\n",
      "dafw_analysis_rec_tc99mm1           1.9214      0.071     26.982      0.000       1.782       2.061\n",
      "==============================================================================\n",
      "Omnibus:                      255.111   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              548.507\n",
      "Skew:                           0.973   Prob(JB):                    7.82e-120\n",
      "Kurtosis:                       5.229   Cond. No.                         7.95\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fitting the short regression model\n",
    "\n",
    "short_reg = smf.ols('y_c_train  ~ has_tmin1_odi + any_insp_prior + \\\n",
    "  any_complaint_tmin13 + num_nonfat_comp_insp_cy_tc99mm1 + \\\n",
    "  initial_pen_cy_mzmm1 + ln_initial_pen_cy_mzmm1 + \\\n",
    "  dafw_analysis_rec_tc99mm1', data=osha_train).fit()\n",
    "print(short_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              y_c_train   R-squared:                       0.475\n",
      "Model:                            OLS   Adj. R-squared:                  0.404\n",
      "Method:                 Least Squares   F-statistic:                     6.731\n",
      "Date:                Mon, 01 Dec 2025   Prob (F-statistic):           5.56e-98\n",
      "Time:                        22:03:57   Log-Likelihood:                -3425.1\n",
      "No. Observations:                1504   AIC:                             7208.\n",
      "Df Residuals:                    1325   BIC:                             8160.\n",
      "Df Model:                         178                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================================\n",
      "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                            0.3440      1.405      0.245      0.807      -2.412       3.100\n",
      "num_yrs_prev_on_sst                  0.1499      0.099      1.521      0.128      -0.043       0.343\n",
      "sic_sector_11                        0.7743      1.107      0.700      0.484      -1.397       2.946\n",
      "sic_sector_21                       10.0621      3.819      2.635      0.009       2.571      17.553\n",
      "sic_sector_31                        1.0490      0.831      1.263      0.207      -0.581       2.679\n",
      "sic_sector_42                        0.8725      0.852      1.024      0.306      -0.799       2.544\n",
      "sic_sector_44                        0.4291      0.875      0.490      0.624      -1.288       2.146\n",
      "sic_sector_48                        1.0071      0.846      1.190      0.234      -0.653       2.668\n",
      "sic_sector_805                       1.5185      0.865      1.756      0.079      -0.178       3.215\n",
      "wp_days_2008                         0.0346      0.099      0.349      0.727      -0.160       0.229\n",
      "has_tmin1_odi                        1.7490      0.860      2.033      0.042       0.061       3.436\n",
      "has_tmin3_odi                        0.9758      0.674      1.448      0.148      -0.347       2.298\n",
      "any_rep_will_viol_4yr               -0.0622      0.517     -0.120      0.904      -1.076       0.952\n",
      "any_complaint_tmin13                 0.3906      0.289      1.353      0.176      -0.176       0.957\n",
      "any_fatcat_tmin13                    0.5828      1.149      0.507      0.612      -1.671       2.837\n",
      "any_insp_prior                       0.0558      0.189      0.295      0.768      -0.316       0.427\n",
      "avg_hours_analysis_tc99mm1           0.2928      2.514      0.116      0.907      -4.639       5.224\n",
      "avg_hours_analysis_tc99mm2          -2.9277      2.995     -0.977      0.329      -8.804       2.949\n",
      "avg_hours_analysis_tc99mm3           1.3088      2.264      0.578      0.563      -3.133       5.751\n",
      "avg_hours_analysis_tc99_2mm1        -1.3047      3.754     -0.348      0.728      -8.669       6.060\n",
      "avg_hours_analysis_tc99_2mm2         3.8177      4.439      0.860      0.390      -4.890      12.525\n",
      "avg_hours_analysis_tc99_2mm3        -1.0550      3.336     -0.316      0.752      -7.599       5.489\n",
      "avg_hours_analysis_tc99_3mm1         0.8610      2.089      0.412      0.680      -3.237       4.959\n",
      "avg_hours_analysis_tc99_3mm2        -1.9473      2.413     -0.807      0.420      -6.680       2.786\n",
      "avg_hours_analysis_tc99_3mm3         0.2418      1.828      0.132      0.895      -3.344       3.827\n",
      "ln_avg_hours_analysismm1             0.2104      0.795      0.265      0.791      -1.349       1.770\n",
      "ln_avg_hours_analysismm2             0.3428      1.100      0.312      0.755      -1.816       2.501\n",
      "ln_avg_hours_analysismm3            -0.5132      0.786     -0.653      0.514      -2.056       1.029\n",
      "count_dafw_analysis_tc99mm1         -0.3396      3.924     -0.087      0.931      -8.037       7.357\n",
      "count_dafw_analysis_tc99mm2         -0.4209      4.303     -0.098      0.922      -8.862       8.020\n",
      "count_dafw_analysis_tc99mm3         -2.0303      3.734     -0.544      0.587      -9.356       5.295\n",
      "count_dafw_analysis_tc99_2mm1        1.7790      4.602      0.387      0.699      -7.250      10.808\n",
      "count_dafw_analysis_tc99_2mm2        0.8177      5.277      0.155      0.877      -9.535      11.170\n",
      "count_dafw_analysis_tc99_2mm3        2.9206      4.623      0.632      0.528      -6.150      11.991\n",
      "count_dafw_analysis_tc99_3mm1       -0.9437      2.220     -0.425      0.671      -5.298       3.410\n",
      "count_dafw_analysis_tc99_3mm2       -0.4893      2.576     -0.190      0.849      -5.542       4.563\n",
      "count_dafw_analysis_tc99_3mm3       -1.4946      2.255     -0.663      0.508      -5.918       2.929\n",
      "ln_count_dafw_analysismm1           -0.4168      2.249     -0.185      0.853      -4.829       3.996\n",
      "ln_count_dafw_analysismm2            2.5918      2.642      0.981      0.327      -2.591       7.775\n",
      "ln_count_dafw_analysismm3            0.5296      2.085      0.254      0.800      -3.562       4.621\n",
      "ln_count_dafw_analysis_2mm1          1.8233      5.135      0.355      0.723      -8.251      11.898\n",
      "ln_count_dafw_analysis_2mm2         -2.5669      5.920     -0.434      0.665     -14.180       9.046\n",
      "ln_count_dafw_analysis_2mm3          0.8345      5.013      0.166      0.868      -9.000      10.669\n",
      "ln_count_dafw_analysis_3mm1         -1.4914      2.718     -0.549      0.583      -6.823       3.841\n",
      "ln_count_dafw_analysis_3mm2          1.6310      3.166      0.515      0.606      -4.579       7.841\n",
      "ln_count_dafw_analysis_3mm3         -0.8527      2.670     -0.319      0.750      -6.091       4.386\n",
      "ln_dafw_analysis_recmm1             -0.1109      1.051     -0.105      0.916      -2.173       1.951\n",
      "ln_dafw_analysis_recmm2             -1.1164      1.135     -0.983      0.326      -3.344       1.111\n",
      "ln_dafw_analysis_recmm3             -0.4784      0.927     -0.516      0.606      -2.297       1.340\n",
      "dafw_analysis_rec_tc99mm1            1.0358      0.934      1.109      0.268      -0.797       2.868\n",
      "dafw_analysis_rec_tc99mm2            1.1405      1.087      1.049      0.294      -0.992       3.273\n",
      "dafw_analysis_rec_tc99mm3            1.3675      0.870      1.573      0.116      -0.338       3.073\n",
      "dafw_analysis_rec_tc99_2mm1          0.1144      0.493      0.232      0.816      -0.852       1.081\n",
      "dafw_analysis_rec_tc99_2mm2          0.0531      0.530      0.100      0.920      -0.986       1.092\n",
      "dafw_analysis_rec_tc99_2mm3         -0.7221      0.473     -1.526      0.127      -1.650       0.206\n",
      "cother_analysis_rec_tc99mm1          0.5173      0.191      2.706      0.007       0.142       0.892\n",
      "cother_analysis_rec_tc99mm2          0.1758      0.317      0.554      0.580      -0.446       0.798\n",
      "cother_analysis_rec_tc99mm3         -0.1705      0.210     -0.813      0.416      -0.582       0.241\n",
      "cother_analysis_rec_tc99_2mm1       -0.3340      0.188     -1.779      0.076      -0.702       0.034\n",
      "cother_analysis_rec_tc99_2mm2       -0.2837      0.211     -1.345      0.179      -0.698       0.130\n",
      "cother_analysis_rec_tc99_2mm3        0.3706      0.209      1.775      0.076      -0.039       0.780\n",
      "ctransfer_analysis_rec_tc99mm1      -0.2200      0.225     -0.976      0.329      -0.662       0.222\n",
      "ctransfer_analysis_rec_tc99mm2       0.1667      0.410      0.406      0.685      -0.638       0.972\n",
      "ctransfer_analysis_rec_tc99mm3       0.2795      0.231      1.211      0.226      -0.173       0.732\n",
      "ctransfer_analysis_rec_tc99_2mm1     0.2435      0.204      1.191      0.234      -0.158       0.645\n",
      "ctransfer_analysis_rec_tc99_2mm2     0.2750      0.247      1.115      0.265      -0.209       0.759\n",
      "ctransfer_analysis_rec_tc99_2mm3    -0.0794      0.217     -0.366      0.714      -0.505       0.346\n",
      "any_deathsmm1                       -0.1261      0.136     -0.926      0.355      -0.393       0.141\n",
      "any_deathsmm2                        0.2660      1.063      0.250      0.802      -1.820       2.352\n",
      "any_strikesmm1                      -0.0556      0.087     -0.643      0.520      -0.225       0.114\n",
      "any_strikesmm2                      -0.3233      1.414     -0.229      0.819      -3.097       2.450\n",
      "any_shutdownmm1                     -0.0820      0.080     -1.022      0.307      -0.240       0.075\n",
      "any_shutdownmm2                      0.4762      0.275      1.734      0.083      -0.063       1.015\n",
      "any_seasonalmm1                     -0.1770      0.081     -2.187      0.029      -0.336      -0.018\n",
      "any_seasonalmm2                      1.0702      0.413      2.592      0.010       0.260       1.880\n",
      "any_disastermm1                      0.0897      0.064      1.402      0.161      -0.036       0.215\n",
      "any_disastermm2                      0.3884      0.883      0.440      0.660      -1.344       2.121\n",
      "any_long_schmm1                      0.1418      0.072      1.956      0.051      -0.000       0.284\n",
      "any_long_schmm2                      0.6103      0.466      1.309      0.191      -0.305       1.525\n",
      "any_illnessmm1                      -0.0574      0.078     -0.738      0.461      -0.210       0.095\n",
      "any_illnessmm2                       0.0353      0.174      0.203      0.839      -0.307       0.377\n",
      "ln_daway_analysismm2                 0.1322      0.120      1.106      0.269      -0.102       0.367\n",
      "ln_dtransfer_analysismm2            -0.2145      0.121     -1.776      0.076      -0.451       0.022\n",
      "paydexmin_netsmm1                   -0.0827      0.097     -0.852      0.395      -0.273       0.108\n",
      "paydexmin_netsmt1                   -0.1929      0.398     -0.485      0.628      -0.973       0.587\n",
      "paydexmin_netsmm2                    0.0715      0.097      0.734      0.463      -0.120       0.263\n",
      "paydexmin_netsmt2                    0.0786      0.390      0.201      0.840      -0.687       0.844\n",
      "ln_sales_netsmm1                    -0.2273      0.412     -0.552      0.581      -1.036       0.581\n",
      "ln_sales_netsmm2                     0.4273      0.421      1.015      0.310      -0.399       1.253\n",
      "ln_sales_netsmt2                     0.4092      0.780      0.524      0.600      -1.122       1.940\n",
      "ln_emp_netsmm1                       0.0038      0.347      0.011      0.991      -0.676       0.684\n",
      "ln_emp_netsmm2                      -0.2501      0.363     -0.689      0.491      -0.962       0.462\n",
      "ln_emp_netsmm3                       0.1179      0.139      0.851      0.395      -0.154       0.390\n",
      "avg_viol_sic3mm1                    -0.1471      0.169     -0.868      0.386      -0.479       0.185\n",
      "avg_viol_sic3mm2                     0.1158      0.168      0.688      0.491      -0.214       0.446\n",
      "avg_viol_sic3mm3                    -0.2780      0.176     -1.582      0.114      -0.623       0.067\n",
      "avg_viol_stmm1                      -0.2407      0.314     -0.767      0.443      -0.856       0.375\n",
      "avg_viol_stmm2                       0.9087      0.440      2.063      0.039       0.045       1.773\n",
      "avg_viol_stmm3                      -0.2976      0.368     -0.809      0.419      -1.020       0.424\n",
      "avg_pen_sic3mm1                      0.2814      0.144      1.953      0.051      -0.001       0.564\n",
      "avg_pen_sic3mm2                      0.0872      0.132      0.660      0.510      -0.172       0.347\n",
      "avg_pen_sic3mm3                      0.0355      0.201      0.176      0.860      -0.360       0.431\n",
      "avg_pen_stmm1                       -0.2763      0.229     -1.204      0.229      -0.726       0.174\n",
      "avg_pen_stmm2                        0.1541      0.257      0.600      0.549      -0.350       0.658\n",
      "avg_pen_stmm3                       -0.0115      0.262     -0.044      0.965      -0.526       0.503\n",
      "avg_gravity_sic3mm1                 -0.1869      0.167     -1.119      0.263      -0.515       0.141\n",
      "avg_gravity_sic3mm2                 -0.1773      0.153     -1.156      0.248      -0.478       0.124\n",
      "avg_gravity_sic3mm3                  0.1725      0.169      1.020      0.308      -0.159       0.504\n",
      "avg_gravity_stmm1                    0.5856      0.345      1.698      0.090      -0.091       1.262\n",
      "avg_gravity_stmm2                   -1.1044      0.520     -2.125      0.034      -2.124      -0.085\n",
      "avg_gravity_stmm3                    0.4326      0.372      1.163      0.245      -0.297       1.162\n",
      "loom_dafw_rec_tc99_s4yrmm1           0.3932      0.205      1.914      0.056      -0.010       0.796\n",
      "loom_dafw_rec_tc99_s4yrmm2           0.1458      0.223      0.655      0.513      -0.291       0.583\n",
      "loom_dafw_rec_tc99_styrmm1          -0.0642      0.376     -0.171      0.864      -0.803       0.674\n",
      "loom_dafw_rec_tc99_styrmm2           0.6017      0.422      1.426      0.154      -0.226       1.429\n",
      "loom_ctransfer_rec_tc99_s4yrmm1     -0.1309      0.152     -0.861      0.389      -0.429       0.167\n",
      "loom_ctransfer_rec_tc99_s4yrmm2     -0.1393      0.156     -0.895      0.371      -0.445       0.166\n",
      "loom_ctransfer_rec_tc99_styrmm1      0.0713      0.355      0.201      0.841      -0.625       0.768\n",
      "loom_ctransfer_rec_tc99_styrmm2     -0.0062      0.365     -0.017      0.987      -0.722       0.710\n",
      "loom_cother_rec_tc99_s4yrmm1        -0.3222      0.239     -1.346      0.178      -0.792       0.147\n",
      "loom_cother_rec_tc99_s4yrmm2         0.1368      0.251      0.546      0.585      -0.355       0.629\n",
      "loom_cother_rec_tc99_styrmm1         0.4205      0.477      0.882      0.378      -0.515       1.356\n",
      "loom_cother_rec_tc99_styrmm2        -0.7499      0.494     -1.517      0.130      -1.720       0.220\n",
      "sd_dafw_rec_tc99_s3yrmm1            -0.4233      0.190     -2.227      0.026      -0.796      -0.050\n",
      "sd_dafw_rec_tc99_s3yrmm2            -0.0626      0.192     -0.327      0.744      -0.438       0.313\n",
      "sd_dafw_rec_tc99_styrmm1             0.0649      0.170      0.382      0.703      -0.269       0.399\n",
      "sd_dafw_rec_tc99_styrmm2            -0.4665      0.262     -1.777      0.076      -0.981       0.048\n",
      "sd_ctransfer_rec_tc99_s3yrmm1        0.2004      0.116      1.720      0.086      -0.028       0.429\n",
      "sd_ctransfer_rec_tc99_s3yrmm2        0.1687      0.124      1.365      0.173      -0.074       0.411\n",
      "sd_ctransfer_rec_tc99_styrmm1       -0.2071      0.267     -0.776      0.438      -0.731       0.317\n",
      "sd_ctransfer_rec_tc99_styrmm2        0.1348      0.260      0.519      0.604      -0.374       0.644\n",
      "sd_cother_rec_tc99_s3yrmm1           0.2162      0.221      0.977      0.329      -0.218       0.650\n",
      "sd_cother_rec_tc99_s3yrmm2          -0.0702      0.210     -0.334      0.738      -0.482       0.342\n",
      "sd_cother_rec_tc99_styrmm1          -0.0904      0.313     -0.289      0.773      -0.704       0.523\n",
      "sd_cother_rec_tc99_styrmm2           0.3615      0.329      1.099      0.272      -0.284       1.007\n",
      "gravity_cy_mzmm1                     0.2608      0.120      2.174      0.030       0.025       0.496\n",
      "gravity_cy_mzmm2                    -0.1157      0.132     -0.876      0.381      -0.375       0.143\n",
      "gravity_cy_mzmm3                    -0.0482      0.100     -0.485      0.628      -0.243       0.147\n",
      "ln_initial_pen_cy_mzmm1             -0.3736      0.159     -2.355      0.019      -0.685      -0.062\n",
      "ln_initial_pen_cy_mzmm2             -0.1213      0.146     -0.828      0.408      -0.409       0.166\n",
      "ln_initial_pen_cy_mzmm3             -0.0304      0.151     -0.201      0.841      -0.327       0.266\n",
      "initial_pen_cy_mzmm1                 0.8792      0.396      2.220      0.027       0.102       1.656\n",
      "initial_pen_cy_mzmm2                 0.0049      0.223      0.022      0.983      -0.433       0.442\n",
      "initial_pen_cy_mzmm3                -0.3697      0.418     -0.884      0.377      -1.190       0.451\n",
      "initial_pen_cy_mz_2mm1              -1.3355      0.446     -2.993      0.003      -2.211      -0.460\n",
      "initial_pen_cy_mz_2mm2               0.0146      0.134      0.109      0.913      -0.249       0.278\n",
      "initial_pen_cy_mz_2mm3               0.4293      0.453      0.948      0.343      -0.459       1.318\n",
      "public_netsmm1                      -0.0882      0.224     -0.394      0.693      -0.527       0.351\n",
      "standalone_netsmm1                  -0.5286      0.212     -2.492      0.013      -0.945      -0.113\n",
      "headquarters_netsmm1                -0.3905      0.260     -1.500      0.134      -0.901       0.120\n",
      "foreign_owned_netsmm1               -0.1802      0.275     -0.655      0.513      -0.720       0.360\n",
      "estab_age_netsmm1                    0.0001      0.243      0.000      1.000      -0.476       0.476\n",
      "estab_age2_netsmm1                   0.1049      0.219      0.478      0.632      -0.325       0.535\n",
      "govt_contractor_netsmm1              0.2477      0.257      0.965      0.335      -0.256       0.751\n",
      "exporter_netsmm1                    -0.0820      0.440     -0.186      0.852      -0.945       0.781\n",
      "importer_netsmm1                     0.1644      0.221      0.743      0.458      -0.270       0.598\n",
      "exp_imp_netsmm1                      0.0263      0.402      0.065      0.948      -0.763       0.815\n",
      "region_dum1                         -0.2947      0.841     -0.350      0.726      -1.944       1.355\n",
      "region_dum2                          0.2475      0.898      0.276      0.783      -1.514       2.010\n",
      "region_dum3                          0.0971      0.787      0.123      0.902      -1.446       1.641\n",
      "region_dum4                         -0.2267      0.822     -0.276      0.783      -1.839       1.385\n",
      "region_dum5                         -0.2695      0.816     -0.330      0.741      -1.869       1.330\n",
      "region_dum6                         -0.1550      0.821     -0.189      0.850      -1.765       1.455\n",
      "region_dum7                         -0.3000      0.835     -0.359      0.720      -1.939       1.339\n",
      "region_dum8                         -0.4031      0.850     -0.474      0.636      -2.071       1.265\n",
      "num_nonfat_comp_insp_cy_tc99mm1     -0.0227      0.074     -0.305      0.760      -0.169       0.123\n",
      "num_nonfat_comp_insp_cy_tc99mm2      0.0577      0.092      0.624      0.532      -0.124       0.239\n",
      "num_nonfat_comp_insp_cy_tc99mm3      0.0339      0.106      0.320      0.749      -0.174       0.242\n",
      "l2_ln_count_dafw_has_tmin3_odi      -0.2675      0.490     -0.545      0.586      -1.230       0.695\n",
      "l2_dafw_has_tmin3_odi                0.0630      0.338      0.186      0.852      -0.601       0.727\n",
      "l2_ctransfer_has_tmin3_odi          -0.3300      0.196     -1.686      0.092      -0.714       0.054\n",
      "l2_cother_has_tmin3_odi             -0.1475      0.168     -0.878      0.380      -0.477       0.182\n",
      "l2_ln_count_dafw_has_tmin1_odi      -0.3183      0.638     -0.499      0.618      -1.570       0.933\n",
      "l2_dafw_has_tmin1_odi               -0.6201      0.521     -1.191      0.234      -1.641       0.401\n",
      "l2_ctransfer_has_tmin1_odi          -0.3215      0.325     -0.989      0.323      -0.959       0.316\n",
      "l2_cother_has_tmin1_odi              0.0809      0.256      0.316      0.752      -0.420       0.582\n",
      "l2_dafw_emp_q2                       0.0040      0.102      0.039      0.969      -0.197       0.205\n",
      "l2_dafw_emp_q3                      -0.0036      0.139     -0.026      0.979      -0.276       0.269\n",
      "l2_dafw_emp_q4                      -0.1654      0.201     -0.824      0.410      -0.559       0.228\n",
      "==============================================================================\n",
      "Omnibus:                      192.556   Durbin-Watson:                   1.957\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              371.277\n",
      "Skew:                           0.795   Prob(JB):                     2.39e-81\n",
      "Kurtosis:                       4.842   Cond. No.                         816.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fitting the long regression model\n",
    "\n",
    "formula_lr = 'y_c_train ~ ' + '+'.join(cols_used)\n",
    "long_reg = smf.ols(formula_lr, data=osha_train).fit()\n",
    "print(long_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 - Fitting the LASSO Model {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third model is the LASSO, which can be implemented with the [LassoCV](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LassoCV.html) function in the `sklearn` library. Run the following code to import this function.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LassoCV\n",
    "```\n",
    "\n",
    "And if needed, you can install `sklearn` by running the following in a separate cell.\n",
    "\n",
    "```python\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "\n",
    "As is common in the machine learning literature, the syntax for applying the LASSO model does not expect a formula notation. The `LassoCV` function takes as arguments model matrices of the type described in parts 3-A and 3-B above. Importantly, these functions also do __not__ require us to explicitly create an intercept column in our data, as this will be included by default.\n",
    "\n",
    "Problem 4-A below asks you to create these matrics.\n",
    "\n",
    "## 4-A: Training and Testing X Matrices {-}\n",
    "\n",
    "Create two new matrices, named `X_train` and `X_test`. These matrices should take the data you created from your training and testing splits respectively, but should exclude all the variables which were excluded from the long-regression. These matrices should have 178 columns. \n",
    "\n",
    "The `X_train` matrix will be used for training the model.\n",
    "The `X_test` matrix can be used to predict our model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the numeric matrices for the data\n",
    "\n",
    "X_train = osha_train.drop(columns=cols_excluded)\n",
    "X_test = osha_test.drop(columns=cols_excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-B Fitting the LASSO Model {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created the matrices in this way, fit a LASSO model with the following code. To make your answer consistent with the solutions be sure to set the random_state to 407.\n",
    "\n",
    "```python\n",
    "mod_lasso = LassoCV(cv=10, random_state=407, max_iter=10**4).fit(X_train, y_c_train)\n",
    "```\n",
    "The `cv=10` argument in the above function call instructs the LASSO to be fit with 10-fold cross-validation to estimate the best value for the $\\lambda$ penalty parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your LASSO Model\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "mod_lasso = LassoCV(cv=10, random_state=407, max_iter=10**4).fit(X_train, y_c_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-C: Extracting Values From the LASSO Model {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different values in the `mod_lasso` object created above. You can access the individual coefficient estimates from the model with the following code:\n",
    "\n",
    "```python\n",
    "mod_lasso.coef_\n",
    "```\n",
    "\n",
    "Running this code will produce an array of the individual estimated coefficient values across all the variables used for prediction (sometimes referred to as features). Using this array, report the following calculations.\n",
    "\n",
    "1. How many coefficients estimated in the LASSO model are non-zero?\n",
    "2. What percentage of coefficients estimated in the LASSO model are non-zero?\n",
    "\n",
    "Hint: various `numpy` or other functions can be applied to the array output, including Boolean operations (>, ==, <, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 coefficients in the LASSO model are non-zero.\n",
      "15.73% of the coefficients estimated in the LASSO model are non-zero.\n"
     ]
    }
   ],
   "source": [
    "# Non-zero coefficient count / mean\n",
    "count = np.sum(mod_lasso.coef_ != 0)\n",
    "print(f'{count} coefficients in the LASSO model are non-zero.')\n",
    "\n",
    "tot_count = len(mod_lasso.coef_)\n",
    "nonzero_percentage = count/tot_count * 100\n",
    "print(f'{nonzero_percentage:.2f}% of the coefficients estimated in the LASSO model are non-zero.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your above calculations compare to the initial linear regressions you ran? If you have fit a linear model, the `.params` attribute can be used to extract the estimated beta coefficients.\n",
    "\n",
    "For both the short and long regression models, report what percentage of the estimated coefficients are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of the estimated coefficients that are non-zero in the regressions are:\n",
      "      - Short: 100.00%\n",
      "      - Long: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Your calculations here:\n",
    "\n",
    "short_coef = short_reg.params\n",
    "tot_count_short = len(short_coef)\n",
    "nonzero_short = np.sum(short_coef != 0)\n",
    "nz_perc_short = nonzero_short/tot_count_short * 100\n",
    "\n",
    "long_coef = long_reg.params\n",
    "tot_count_long = len(long_coef)\n",
    "nonzero_long = np.sum(long_coef != 0)\n",
    "nz_perc_long = nonzero_long/tot_count_long * 100\n",
    "\n",
    "print(f'''The percentage of the estimated coefficients that are non-zero in the regressions are:\n",
    "      - Short: {nz_perc_short:.2f}%\n",
    "      - Long: {nz_perc_long:.2f}%''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 - Evaluating Performance {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-A: MSE In the Training Sample {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the predictive performance for each model (on the training set) by computing the Mean Squared Error (MSE) between the predicted value and the observed outcome, and enter these values into the first column of the below table in 5-C.\n",
    "\n",
    "When filling in the table, please round your numbers to 2 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may calculate the MSE by hand using formulas presented in class (as shown with code in Problem Set 6) or by defining a function yourself. Alternatively, you may find it convenient to load in the `mean_squared_error` function from the `sklearn` package with the following code. You can read the documentation for this function [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html).\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "```\n",
    "\n",
    "Note: Problem 6 Set demonstrated how to calculate and get predictions for linear models fit from the `statsmodels` library. For the LASSO model, your model object will contain a method `.predict()` which will estimate predicted values applying the model to new data. To get LASSO predictions on the training data, you can apply this prediction method to the training data itself, using:\n",
    "\n",
    "```python\n",
    "mod_lasso.predict(X_train)\n",
    "```\n",
    "\n",
    "Similarly, to obtain predictions on the testing data, you can update the above code so that the new data you are predicting to is the testing data.\n",
    "\n",
    "```python\n",
    "mod_lasso.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE short: 7.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculating MSE in the training sample for the short-regression\n",
    "\n",
    "y_short_train = short_reg.predict(osha_train)\n",
    "mse_short_train = mean_squared_error(y_c_train, y_short_train)\n",
    "print(f\"MSE short: {mse_short_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE long: 5.57\n"
     ]
    }
   ],
   "source": [
    "# Calculating MSE in the training sample for the long-regression\n",
    "\n",
    "y_long_train = long_reg.predict(osha_train)\n",
    "mse_long_train = mean_squared_error(y_c_train, y_long_train)\n",
    "print(f\"MSE long: {mse_long_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE LASSO: 6.32\n"
     ]
    }
   ],
   "source": [
    "# Calculating MSE in the training sample for the LASSO regression\n",
    "\n",
    "y_lasso_train = mod_lasso.predict(X_train)\n",
    "mse_lasso_train = mean_squared_error(y_c_train, y_lasso_train)\n",
    "print(f\"MSE LASSO: {mse_lasso_train:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-B: MSE In the Testing (Hold-out) Sample {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the procedures in 5-A, but this time use your fitted models to predict for the test (hold-out) set. Note that you will need to use the equivalent of `X_train` but for the test set `X_test`. Report your final results by entering the test-set MSE in the second column of Table 5-C. Remember you will be using the parameters you estimated using observations in the training set to make predictions about the observations in the test set.\n",
    "\n",
    "When filling in the table, please round your numbers to 2 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE short: 7.99\n",
      "MSE long: 7.78\n",
      "MSE LASSO: 7.28\n"
     ]
    }
   ],
   "source": [
    "# Calculating MSE in the holdout sample \n",
    "\n",
    "# Short regression\n",
    "y_short_test = short_reg.predict(osha_test)\n",
    "mse_short_test = mean_squared_error(y_c_test, y_short_test)\n",
    "print(f\"MSE short: {mse_short_test:.2f}\")\n",
    "\n",
    "# Long regression\n",
    "y_long_test = long_reg.predict(osha_test)\n",
    "mse_long_test = mean_squared_error(y_c_test, y_long_test)\n",
    "print(f\"MSE long: {mse_long_test:.2f}\")\n",
    "\n",
    "# LASSO\n",
    "y_lasso_test = mod_lasso.predict(X_test)\n",
    "mse_lasso_test = mean_squared_error(y_c_test, y_lasso_test)\n",
    "print(f\"MSE LASSO: {mse_lasso_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-C: Summary Table {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Model      | In-Sample MSE | Hold-out MSE |\n",
    "|----------     | ------------- | ------------ |\n",
    "| Short         |     7.08      |     7.99     |\n",
    "| Long          |     5.57      |     7.78     |\n",
    "| LASSO         |     6.32      |     7.28     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-D: Your Conclusions {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are three key conclusions you draw from the above Table regarding your ability to predict injury rates (1-2 paragraphs)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your conclusions here:_\n",
    "\n",
    "First, we can conclude that `the LASSO and the Long regressions` are the two best alternatives, as the Long's in-sample MSE is the lowest (5.57), and the LASSO's hold-out MSE is the lowest as well (7.28), especially compared to the Short one.\n",
    "\n",
    "The Long model shows overfitting: while it performs better in-sample, its hold-out MSE is actually worse than the LASSO and only marginally better than the Short model. This suggests that including all 178 predictors improves fit to the training data but does not improve predictive power on unseen data, and might introduce noise.\n",
    "The Short regression exhibits the weakest predictive performance overall.\n",
    "\n",
    "The LASSO model has a better balance between the two, improving from the other two models, also avoiding overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 - Estimating Binary Outcomes {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections, you predicted a continuous variable (`injury_rate`). The next set of questions are about predicting a binary variable (`high_injury_rate`). Rather than aim to estimate specific injury rates at all locations, this type of binary model focuses on classification of a site as having a high injury rate, but not estimating the actual injury rate.\n",
    "\n",
    "This problem will walk you through code to generate predictions from a Logistic Regression. The focus here will not be on the exact code of the Logistic Regression, but you will use predictions from these models to calculate and report precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-A: Fitting Logistic Models {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression can be fit using functionality from `sklearn` by loading the following function.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "```\n",
    "\n",
    "Like the LASSO regression, this model will expect as inputs matrix representations of the data. The following blocks of code create these matrices (for the short regression, we can use the same matrices generated earlier for the long regression) and also save down the outcome variables we are interested in. We can use the same training / testing split from above.\n",
    "\n",
    "Run this code before moving on to the next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Saving down the new outcome variables\n",
    "y_b_train = osha_train['high_injury_rate']\n",
    "y_b_test = osha_test['high_injury_rate']\n",
    "\n",
    "# Creating a matrix format for the short regression, both the training and testing versions\n",
    "X_train_short = osha_train.loc[:,['has_tmin1_odi', 'any_insp_prior', 'any_complaint_tmin13', 'num_nonfat_comp_insp_cy_tc99mm1',\n",
    "                        'initial_pen_cy_mzmm1', 'ln_initial_pen_cy_mzmm1', 'dafw_analysis_rec_tc99mm1']]\n",
    "\n",
    "X_test_short = osha_test.loc[:,['has_tmin1_odi', 'any_insp_prior', 'any_complaint_tmin13', 'num_nonfat_comp_insp_cy_tc99mm1',\n",
    "                        'initial_pen_cy_mzmm1', 'ln_initial_pen_cy_mzmm1', 'dafw_analysis_rec_tc99mm1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-B: Fitting Basic Logistic Regressions {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code fits basic logistic regressions for both the long and short regressions, and a logistic regression with cross-validation and a LASSO penalty. Run this code before moving on to the next exercises.\n",
    "\n",
    "Note, the LASSO regression may take a few minutes to fit (depending on your computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Fitting the short model\n",
    "fit_short_b = LogisticRegression(max_iter=10**3).fit(X_train_short, y_b_train)\n",
    "\n",
    "# Fitting the long model\n",
    "fit_long_b = LogisticRegression(max_iter=10**3).fit(X_train, y_b_train)\n",
    "\n",
    "# Fitting a model with a LASSO penalty\n",
    "fit_lasso_b = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear', random_state=0, max_iter=10**4).fit(X_train, y_b_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-C: Extracting Predicted Probabilities {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models you just fit can be used to generate predicted probabilities of whether a site will have a value of `1` for the `high_injury_rate` variable or a `0`. The predicted probabilities of having `high_injury_rate` can be calculated and extracted with the `.predict_proba()` method. The below code extracts and saves these probabilities for all three models (short, long, LASSO) for the training data. This information will be needed later to calculate precision and recall. Run this code, and then modify it as needed to similarly save predicted probabilities for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA PREDICTIONS\n",
    "\n",
    "# Predictions from the short regression\n",
    "p_short_train = fit_short_b.predict_proba(X_train_short)[:,1]\n",
    "# Predictions from the long regression\n",
    "p_long_train = fit_long_b.predict_proba(X_train)[:,1]\n",
    "# Predictions from the LASSO regression\n",
    "p_lasso_train = fit_lasso_b.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING DATA PREDICTIONS\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "# Short regression\n",
    "p_short_test = fit_short_b.predict_proba(X_test_short)[:,1]\n",
    "# Long regression\n",
    "p_long_test = fit_long_b.predict_proba(X_test)[:,1]\n",
    "# LASSO regression\n",
    "p_lasso_test = fit_lasso_b.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can work with these arrays of predicted probabilities individually or you may prefer to save them together in a single Data Frame along with the true outcomes `y_b_train` and `y_b_test`. You may use the space below to create this DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the predictions in a DataFrame\n",
    "\n",
    "df_training = pd.DataFrame(\n",
    "    {\n",
    "        'Short Train Probabilities': p_short_train,\n",
    "        'Long Train Probabilities': p_long_train,\n",
    "        'LASSO Train Probabilities': p_lasso_train\n",
    "    }\n",
    ")\n",
    "\n",
    "df_testing = pd.DataFrame(\n",
    "    {\n",
    "        'Short Test Probabilities': p_short_test,\n",
    "        'Long Test Probabilities': p_long_test,\n",
    "        'LASSO Test Probabilities': p_lasso_test\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-D: Estimating Binary Outcomes {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above predicted probabilities can be used to identify high-risk sites. The default behavior for the `sklearn` logistic models is to predict the binary outcome variable to be a `1` wherever this predicted probability exceeds 50%. Given the limited budget of OSHA however we may not be able to go to all sites. Further, OSHA may also wish to go to a site where the predicted probability is below 50% if that site is still one of the highest predicted probabilities in our data set. Given the budget constraint, we could instead focus on the __top 30%__ of the sites with the highest predicted probabilities within each category.\n",
    "\n",
    "A pandas DataFrame has a `.quantile()` method, or the numpy library has the `numpy.quantile()` function. Using these functions (or another approach you are comfortable with), for each of the three models (short, long, LASSO) and the two data sets (training and testing), create new variables which store the _binary predictions_ (values of `0` or `1`) for the `high_injury_rate` variable where the top 30% of predicted probabilities __within each model__ are estimated to a value of `1` (denoting high injury) and the bottom 70% of predicted probabilities __within each model__ are estimated to a value of `0`.\n",
    "\n",
    "At the end of this process, you should have 3 different binary estimates (one for each of the short, long and LASSO models) for each observation across the two different samples (training and testing).\n",
    "\n",
    "The quantile calculation should be done within each of these six separate categories (e.g. for your binary predictions on the training data for the short regression model, you should examine the top 30% of predicted probabilities for the short regression model in the training data).\n",
    "\n",
    "Hint: you can use a Boolean operator (<, >, ==, etc.) to compare all values in a specific column or array to a single calculated value (such as the desired quantile thresholds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "for col in df_training.columns:\n",
    "    threshold_train = df_training[col].quantile(.7)\n",
    "    df_training[f\"{col} Binary\"] = (df_training[col] >= threshold_train).astype(int)\n",
    "\n",
    "for col in df_testing.columns:\n",
    "    threshold_test = df_testing[col].quantile(.7)\n",
    "    df_testing[f\"{col} Binary\"] = (df_testing[col] >= threshold_test).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-E: Calculating Precision and Recall {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While MSE is a common measure of model accuracy for continuous outcomes, when working with binary outcomes in a classification problem, _precision_ and _recall_ are more popular measures. These measures were defined in the case study and in class.\n",
    "\n",
    "With your above calculations, you have the true values for the outcome (which were stored as `y_b_train` and `y_b_test` when fitting the models), and the corresponding predictions based on the 30% cutoff.\n",
    "\n",
    "Using these values, calculate and report the precision and recall for each model both within the training sample and the testing sample and fill in the below table.\n",
    "\n",
    "You may calculate these values using the formulas provided in the case study. Alternatively you may wish to use functions provided in the `sklearn` package which can be loaded with the following code:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "```\n",
    "\n",
    "You may read the documentation for these functions at: [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) and [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Training dataframe\n",
      "    - Short precision and recall: 0.75, 0.51;\n",
      "    - Long precision and recall: 0.84, 0.57;\n",
      "    - LASSO precision and recall: 0.78, 0.53.\n",
      "    \n",
      "\n",
      "    Testing dataframe\n",
      "    - Short precision and recall: 0.76, 0.53;\n",
      "    - Long precision and recall: 0.76, 0.53;\n",
      "    - LASSO precision and recall: 0.77, 0.54.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "# TRAINING\n",
    "\n",
    "    # Short\n",
    "y_pred_short_train = df_training['Short Train Probabilities Binary']\n",
    "precision_train_short = precision_score(y_b_train, y_pred_short_train)\n",
    "recall_train_short = recall_score(y_b_train, y_pred_short_train)\n",
    "\n",
    "    # Long\n",
    "y_pred_long_train = df_training['Long Train Probabilities Binary']\n",
    "precision_train_long = precision_score(y_b_train, y_pred_long_train)\n",
    "recall_train_long = recall_score(y_b_train, y_pred_long_train)\n",
    "\n",
    "    # LASSO\n",
    "y_pred_lasso_train = df_training['LASSO Train Probabilities Binary']\n",
    "precision_train_lasso = precision_score(y_b_train, y_pred_lasso_train)\n",
    "recall_train_lasso = recall_score(y_b_train, y_pred_lasso_train)\n",
    "\n",
    "print(\n",
    "    f'''\n",
    "    Training dataframe\n",
    "    - Short precision and recall: {precision_train_short:.2f}, {recall_train_short:.2f};\n",
    "    - Long precision and recall: {precision_train_long:.2f}, {recall_train_long:.2f};\n",
    "    - LASSO precision and recall: {precision_train_lasso:.2f}, {recall_train_lasso:.2f}.\n",
    "    '''\n",
    ")\n",
    "\n",
    "\n",
    "# TESTING\n",
    "\n",
    "    # Short\n",
    "y_pred_short_test = df_testing['Short Test Probabilities Binary']\n",
    "precision_test_short = precision_score(y_b_test, y_pred_short_test)\n",
    "recall_test_short = recall_score(y_b_test, y_pred_short_test)\n",
    "\n",
    "    # Long\n",
    "y_pred_long_test = df_testing['Long Test Probabilities Binary']\n",
    "precision_test_long = precision_score(y_b_test, y_pred_long_test)\n",
    "recall_test_long = recall_score(y_b_test, y_pred_long_test)\n",
    "\n",
    "    # LASSO\n",
    "y_pred_lasso_test = df_testing['LASSO Test Probabilities Binary']\n",
    "precision_test_lasso = precision_score(y_b_test, y_pred_lasso_test)\n",
    "recall_test_lasso = recall_score(y_b_test, y_pred_lasso_test)\n",
    "\n",
    "print(\n",
    "    f'''\n",
    "    Testing dataframe\n",
    "    - Short precision and recall: {precision_test_short:.2f}, {recall_test_short:.2f};\n",
    "    - Long precision and recall: {precision_test_long:.2f}, {recall_test_long:.2f};\n",
    "    - LASSO precision and recall: {precision_test_lasso:.2f}, {recall_test_lasso:.2f}.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Model      | Training Precision | Training Recall |\n",
    "|----------     | -------------      | ------------    |\n",
    "| Short         |    0.75                |     0.51            |\n",
    "| Long          |        0.84            |       0.57          |\n",
    "| LASSO         |            0.78        |           0.53      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Model      | Testing Precision | Testing Recall |\n",
    "|----------     | -------------       | ------------     |\n",
    "| Short         | 0.76         |       0.53          |\n",
    "| Long          |      0.76              |     0.53             |\n",
    "| LASSO         |          0.77          |     0.54            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7 - Final Thoughts {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-A: Selecting an Approach {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of your tables in Problem 5 and Problem 6, OSHA asks you to indicate which of your prediction algorithms you would recommend using to select the sites they should inspect and why (2-3 paragraphs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your selection here:_\n",
    "\n",
    "My suggestion would be to use the `LASSO model`: although all three prediction methods perform similarly on the test sample, LASSO achieves the strongest balance between accuracy and generalizability. In particular, it attains the highest testing precision (0.77) and recall (0.54), indicating that it is slightly more effective at identifying establishments that truly face a high injury risk. This means OSHA would be better able to target inspections toward the workplaces that most warrant regulatory attention, while reducing the number of unnecessary inspections of low-risk sites.\n",
    "\n",
    "Compared to the Long regression model — the alternative closest to it — the advantages of LASSO become clear, as the Long model exhibits signs of overfitting, performing very well on the training data but losing much of that performance on the test set. This suggests that it captures noise rather than stable, predictive patterns. By contrast, the LASSO penalty helps control model complexity and improves its out-of-sample stability. As a result, LASSO provides more reliable predictions for new data, making it a more suitable and operationally robust choice for OSHA’s inspection strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-B: OSHA's Current Approach {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given OSHA’s current approach of choosing randomly to inspect 30% of sites, __compute the precision and recall of their current approach__. Note: You will not need to use python or the data set to answer this question. The goal is that you apply the definition of precision and recall to OSHA’s current algorithm.\n",
    "\n",
    "From the full data, the proportion of sites in the full sample that have a high injury rate is 44%. Adding notation, we can define the above facts as:\n",
    "\n",
    "- Pr(High Injury) = 0.44\n",
    "- Pr(Selected) = 0.30\n",
    "\n",
    "The current approach of random selection assumes these two probabilities are independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your calculation here:_\n",
    "\n",
    "$Recall=Pr(Selected|High\\ \\ Injury)=Pr(S \\cap\\ H)/Pr(H)=(0.30*0.44)/0.44=0.30$\n",
    "\n",
    "$Precision=Pr(High\\ \\ Injury|Selected)=Pr(H \\cap\\ S)/Pr(S)=(0.44*0.30)/0.30=0.44$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-C: Comparing your Precision and Recall Rates {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly compare precision and recall from your models compared to OSHA's current approach (1 paragraph).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here:_\n",
    "\n",
    "The values calculated – assuming that the probabilities are independent – are:\n",
    "- `Recall = 0.30`\n",
    "- `Precision = 0.44`\n",
    "\n",
    "These are significantly lower than the ones obtained in the Training and Testing calculations, especially compared to the LASSO values, closer to (but still lower than) the Short regression model's results.\n",
    "\n",
    "Compared to OSHA’s current random-selection approach, the predictive models all perform meaningfully better. The random method cannot exploit any information in the data, leading to low accuracy in identifying truly high-risk sites. In contrast, the LASSO model achieves substantially higher recall and precision, indicating that it is far more effective at detecting establishments with elevated injury rates while reducing false positives. Even the Short regression model, although less accurate than LASSO, surpasses the performance of the current approach. Overall, this comparison shows that OSHA’s existing method is considerably less efficient than the data-driven predictive alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-D: Additional Considerations {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OSHA would need to overcome several operational and political obstacles in order to change their algorithm for targeting which sites to inspect. They ask you to explain to them how much better the algorithm you chose performs relative to their status quo operation. How would you respond? [1 paragraph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here:_\n",
    "\n",
    "The difference between the actual random method and the (superior) LASSO approach is that random selection cannot leverage predictive patterns in the data. Adopting a predictive algorithm like LASSO would lead to more efficient resource allocation and better identification of high-risk workplaces.\n",
    "\n",
    "The LASSO model, operating with the same inspection budget, offers superior performance with a Recall of 0.54 and Precision of 0.77. Compared to random selection (which would achieve approximately 0.30 recall and 0.44 precision), this represents a substantial improvement in both metrics, meaning OSHA could inspect the same number of sites while identifying significantly more high-risk workplaces and reducing false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 0 - AI Promts {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used GenAI assistance in completing this problem set, please include the prompts you used below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-C:\n",
    "_Are these answers reliable, even if all at 100%?_\n",
    "\n",
    "(From my results) _The percentage of the estimated coefficients that are non-zero in the regressions are:_\n",
    "\n",
    "   _- Short: 100%_\n",
    "\n",
    "   _- Long: 100%_\n",
    "\n",
    "#### 6-B:\n",
    "\n",
    "(Before fixing my code, I had troubles with running the command) _The command below does not work, is it okay if I increase the number of iterations?_\n",
    "\n",
    "_Command:_\n",
    "\n",
    "_fit_short_b = LogisticRegression(max_iter=10**3).fit(X_train_short, y_b_train)_\n",
    "\n",
    "_fit_long_b = LogisticRegression(max_iter=10**3).fit(X_train, y_b_train)_\n",
    "\n",
    "_(...)_\n",
    "\n",
    "As a result, I increased the iterations of the long model. After fixing the code – due to a mistake – I brought the iterations number back to its initial amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 63387_PP422.ipynb to html\n",
      "[NbConvertApp] Writing 461065 bytes to 63387_PP422.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html \"63387_PP422.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
