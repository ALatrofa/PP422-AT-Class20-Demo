{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions {-}\n",
    "\n",
    "1. Download the provided jupyter notebook file to your computer.\n",
    "2. Write all your answers and code into this notebook file.\n",
    "3. When your work is completed, export your notebook to an HTML file.\n",
    "4. Submit your HTML file and a copy of the notebook to the assignment page on Moodle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification {-}\n",
    "\n",
    "### Your Information {-}\n",
    "\n",
    "Your Last Name:\n",
    "Latrofa\n",
    "\n",
    "Your First Name:\n",
    "Ania\n",
    "\n",
    "### Group Members (list any classmates you worked with on this problem set) {-}\n",
    "\n",
    "Your Group Members:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading initial packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Packages for running a linear regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Estimating Impacts on Steps, Part II {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your previous problem set, I asked you to analyze a data set to estimate the effects of a program to increase the number of steps people take a day. Most answers included a comparison of means between the treatment and control groups or a bivariate regression, and concluded that the program had a statistically significant effect of 2,793 steps. \n",
    "\n",
    "_The goal of this problem set question is to help you see the importance of exploratory data analysis and visualization __before__ running any regressions._\n",
    "\n",
    "Recall the setup of the problem:\n",
    "\n",
    "You have designed and implemented a randomized control trial (RCT), where you track peoples’ steps with a pedometer for 3 initial weeks. After this tracking period, participants in the study were divided into a treatment and control group. The treatment group got a push notification on their phone telling them their average step count over the initial weeks, while no message was sent to the control group. You then recorded total steps after 1 additional week from when this notification was sent out.\n",
    "\n",
    "The data set `Steps.csv` contains the data from the study. It includes the following variables:\n",
    "\n",
    "* `treatment` – a binary indicator of whether a participant was in the treatment or control group\n",
    "* `BaselineSteps` – the total number of steps recorded after the initial 3 weeks\n",
    "* `PostSteps` – the total number of steps recorded after 4 weeks. Note, this value includes the BaselineSteps, plus the additional steps taken in the final week (after treatment was administered)\n",
    "* `StepChange` – the change in steps between the `PostSteps` and `BaselineSteps` measurements. This is equal to the number of new steps taken in the final week of the program\n",
    "\n",
    "The same file `Steps.csv` has been provided. Read in this data set and then answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "steps = pd.read_csv('/Users/anialatrofa/Desktop/London School of Economics/Y1/AT/Study Material/PP422/Python/Data/W7 (6) Steps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-A {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If properly conducted, a randomized control trial (RCT) helps ensure that the treatment and control groups are equivalent at baseline. If these groups are equivalent at baseline, this helps us attribute a causal effect to the treatment we are studying. Is there evidence in the data that supports this claim? To answer this question, compare the average number of steps at baseline between treatment and control groups. Is the difference between the two groups statistically significant? What does this say about the credibility of this RCT?\n",
    "\n",
    "Hint: for statistical significance, you may use either a regression analysis or a t-test for the difference in means. Code for both of these approaches were introduced in prior problem sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          BaselineSteps   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     46.09\n",
      "Date:                Sun, 16 Nov 2025   Prob (F-statistic):           1.19e-11\n",
      "Time:                        17:17:09   Log-Likelihood:            -1.3764e+05\n",
      "No. Observations:               11363   AIC:                         2.753e+05\n",
      "Df Residuals:                   11361   BIC:                         2.753e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   7.551e+04    568.779    132.762      0.000    7.44e+04    7.66e+04\n",
      "treatment  -5624.8534    828.533     -6.789      0.000   -7248.922   -4000.785\n",
      "==============================================================================\n",
      "Omnibus:                      856.185   Durbin-Watson:                   1.984\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1057.995\n",
      "Skew:                           0.744   Prob(JB):                    1.82e-230\n",
      "Kurtosis:                       2.849   Cond. No.                         2.56\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Comparing the difference in baseline steps:\n",
    "\n",
    "model = smf.ols('BaselineSteps ~ treatment', data=steps).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here:_\n",
    "\n",
    "The regression shows that the p-value of treatment is below 5%, which means that the difference between the two groups at baseline is statistically significant. We can deduct that there might be issues with the RCT we are relying on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-B {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s focus on the outcome variable (`StepChange`), which measures the number of steps that people took in the final week of the program. \n",
    "\n",
    "1.  What would you expect to be the shape of the distribution of this variable (that is, what shape would you expect a histogram to look like)?\n",
    "2.  After stating your expectation, create a histogram of this variable. Is this what you expected? What does this say about the credibility of the outcome variable used in this RCT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your expected distribution and explanation here:_\n",
    "\n",
    "I would expect the distribution to be approximately normal, with only a few positive or negative values at the extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your histogram here:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(steps['StepChange'], bins=30, edgecolor='black')\n",
    "plt.xlabel('Step Change')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Step Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-C {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What lessons do you draw from this exercise as you think about the next time you are about to start running regressions on a data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here [maximum one paragraph]:_\n",
    "\n",
    "Next time, I would explore the data more in detail, because analysis early on could help understand better if there are issues to be expected, or if there might be issues with the data (so that we could approach the problem differently)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-D The REAL Data Set {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the data set you analyzed is a masked version of a data set that was used to produce an influential paper that argued that dishonesty can be reduced by asking people to sign a statement of honest intent before providing information (_i.e._, at the top of a document) rather than after providing information (_i.e._, at the bottom of a document). The paper was based on a field experiment conducted by an auto insurance company in the southeastern United States. Customers were asked to report the current odometer reading of up to four cars covered by their policy. They were randomly assigned to sign a statement indicating, “I promise that the information I am providing is true” either at the top or bottom of the form. \n",
    "\n",
    "Customers assigned to the 'sign-at-the-top' condition reported driving 2,400 more miles than those assigned to the 'sign-at-the-bottom' condition. This was seen as evidence that signing at the top could be a cheap and effective way of reducing dishonesty.\n",
    "\n",
    "The data set you analyzed across these problem sets is the one used in this paper except that I referred to the outcome as steps taken rather than miles driven, and I focused on the odometer reading of the first car only (hence the impact you found was slightly different than the one reported in the paper). \n",
    "\n",
    "The analysis you conducted above plus some additional analyses provided compelling evidence that the findings from the original paper were not real and were partially based on fake data. [This posting](https://datacolada.org/98) goes over many of the details, and there has been recent follow-up reporting by the [Financial Times](https://www.ft.com/content/64f76797-d390-45fd-b00f-2cab6412bdcb). The authors of the paper retracted the original publication, and several of them issued personal replies to the posting. This controversy raised important issues about data analysis, reproducibility of research findings, detection of fake data, and admission of error.\n",
    "\n",
    "Feel free to comment on the Moodle [forum](https://moodle.lse.ac.uk/mod/hsuforum/view.php?id=1809615) with your views about any of these issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Bootstrap Estimates of Income Inequality {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different measures of income inequality, including comparisons between the mean and median income, the income share of the top 1%, and measures like the Gini coefficient. An alternative way to measure inequality is the “P90/P10” ratio, which calculates the ratio of the 90th percentile of income to the 10th percentile of income. This is also sometimes referred to as the ratio of the top 10% to the bottom 10%.\n",
    "\n",
    "This problem asks you to evaluate this measure of income inequality using the survey information from South Africa that you used in a previous problem set. The problems will walk you through how to apply a bootstrap procedure to generate confidence intervals for a new estimator where the Central Limit Theorem may not apply.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-0: Data Cleaning {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the provided `palms_clean.csv` data, which is identical to what you used in your previous problem set.\n",
    "\n",
    "As a reminder, the `imputed_real` variable contains information on real monthly income. We will use this variable as the basis for our analysis of income inequality. Other variables include:\n",
    "\n",
    "1. `Popgroup` – respondent population group. This is a numeric variable corresponding to the following categories:\n",
    "    * `1` African/Black\n",
    "    * `2` Coloured\n",
    "    * `3` Indian/Asian\n",
    "    * `4` White\n",
    "    * `5` Other\n",
    "    * `9` Unspecified\n",
    "2. `Gender`- respondent gender, which the data collection agency only divided into Male / Female. The numeric coding of this variable corresponds to:\n",
    "    * `1` Male\n",
    "    * `2` Female\n",
    "    * `9` Unspecified\n",
    "\n",
    "\n",
    "Clean the data in the following ways:\n",
    "\n",
    "1. Drop rows that contain `NA` values for the `imputed_real` variable\n",
    "2. Recode the `popgroup` variable to be a categorical type with informative category names (you may reuse your code from Problem Set 4 here).\n",
    "3. Save the index as a separate column in the dataset which can act as a unique identifier for each row. You can achieve this with the `.reset_index()` method, or by extracting and saving the index directly with the `.index` attribute. It will be helpful to have these unique identifiers for later portions of the analysis, and you may find it easier to work with them if they are stored in a column instead of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in and cleaning your data\n",
    "\n",
    "palms = pd.read_csv('/Users/anialatrofa/Desktop/London School of Economics/Y1/AT/Study Material/PP422/Python/Data/W7 (6) palms_clean.csv')\n",
    "\n",
    "palms = palms.dropna(subset=['imputed_real'])\n",
    "\n",
    "palms['population group'] = palms['popgroup'].astype('category').cat.rename_categories(\n",
    "    {1: 'African/Black',\n",
    "     2: 'Coloured',\n",
    "     3: 'Indian/Asian',\n",
    "     4: 'White',\n",
    "     5: 'Other',\n",
    "     9: 'Unspecified'}\n",
    ")\n",
    "palms.drop('popgroup', inplace=True, axis=1)\n",
    "\n",
    "palms['employment status'] = palms['empstat1'].astype('category').cat.rename_categories(\n",
    "    {1: 'Employed',\n",
    "     2: 'Unemployed',\n",
    "     0: 'Not economically active'}\n",
    ")\n",
    "palms.drop('empstat1', inplace=True, axis=1)\n",
    "\n",
    "palms['sex'] = palms['gender'].astype('category').cat.rename_categories(\n",
    "    {1: 'Male',\n",
    "     2: 'Female',\n",
    "     9: 'Unspecified'}\n",
    ")\n",
    "palms.drop('gender', inplace=True, axis=1)\n",
    "\n",
    "palms = palms.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-A: Inequality in the Full Sample {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the provided data, calculate the 90:10 ratio in the full sample of your data for the `imputed_real` variable. You may calculate this value in a variety of ways. First, a pandas DataFrame has a `.quantile()` method which will calculate a quantile value at a desired level. Alternatively, the `numpy` package has a function `np.quantile()` which can be applied to an array to calculate similar values.\n",
    "\n",
    "Report and interpret this value. Does this value seem large to you? Search online for this measure from your home country and report that as well. Note, some online sources may refer to this value as the \"R/P 10%\", referring to the ratio of the richest and poorest 10% of the population.\n",
    "\n",
    "Hint: you will need to calculate this 90:10 ratio several times over the course of this problem and you may find it helpful to define a function which will perform this calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 90:10 ratio is 23.41\n"
     ]
    }
   ],
   "source": [
    "# Your calculation here:\n",
    "\n",
    "p90 = palms['imputed_real'].quantile(0.90)\n",
    "p10 = palms['imputed_real'].quantile(0.10)\n",
    "ratio_9010 = p90 / p10\n",
    "\n",
    "print(f\"The 90:10 ratio is {ratio_9010:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here:_\n",
    "\n",
    "In `Italy`, online sources report the R/P 10% ratio to be around `10`, meaning that the richest 10% in the country earn roughly 10 rimes what the poorest earn. Italy's ratio is quite lower than the one obtained from our dataset, meaning that there might be a higher level of inequality in South Africa, compared to Italy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-B: Inequality by Subgroups {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided dataset also contains information on the population group for the respondents. Using this variable, calculate and report the 90:10 ratio for each population group using the full data sample. Comment on the patterns of inequality based on this subgroup calculation. Which group exhibited the highest inequality in our sample? Which group exhibited the lowest inequality in our sample?\n",
    "\n",
    "Hint: you can use the `.groupby()` and `.apply()` methods to apply a function to each categorization. You could also use a for loop to replicate the calculation for different subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African/Black: 20.18\n",
      "Coloured: 15.38\n",
      "White: 19.83\n",
      "Indian/Asian: 19.83\n"
     ]
    }
   ],
   "source": [
    "# Your calculation here:\n",
    "\n",
    "def calculate_9010_ratio(data):\n",
    "    p90 = data.quantile(0.90)\n",
    "    p10 = data.quantile(0.10)\n",
    "    return p90 / p10\n",
    "\n",
    "for group in palms['population group'].unique():\n",
    "    subset = palms[palms['population group'] == group]['imputed_real']\n",
    "    ratio = calculate_9010_ratio(subset)\n",
    "    print(f\"{group}: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here_\n",
    "\n",
    "In our sample, the African/Black group exhibits the highest level of inequality (at `20.18`), whereas the Coloured group shows the lowest level (at `15.38`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-C: Taking a Single Bootstrap {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences by group you calculated above could be due to sampling fluctuations. Ideally, we would like to calculate confidence intervals for our estimates to test if these differences are statistically significant, but no simple formula exists for confidence intervals for an estimator like the 90:10 ratio or the difference in this ratio between two groups.\n",
    "\n",
    "One way to estimate these confidence intervals is by constructing a __bootstrap sample__. The remainder of this problem set guides you through this procedure. First, consider the 90:10 ratio in the full sample that you calculated in part 2a above. With the full data, complete the following steps:\n",
    "\n",
    "1. Calculate how many unique observations the full data set has. Save this total size of the data as a variable `n`. \n",
    "2. Set the random seed using `numpy` by running the following code (assuming `numpy` has been imported with the alias `np`):\n",
    "```python\n",
    "np.random.seed(422)\n",
    "```\n",
    "3. Draw a sample of rows of size `n` from the full data set __with replacement__. Save this bootstrap sample as a new object named `palms_bs`. \n",
    "4. Report how many total rows are in this `palms_bs` sample. How many unique rows are in this sample `palms_bs` (hint, look at the unique values in your index id variable)?\n",
    "5. Using the `palms_bs` sample, calculate and report the 90:10 ratio in this newly simulated data. How does it compare to the value you calculated for the full data set?\n",
    "\n",
    "\n",
    "Hint: There are a few general approaches you can take to draw a random sample with replacement. You can use the `.sample()` method on a pandas DataFrame to draw a random sample of rows. Be sure to set 'replace=True' as an argument to have the sample be drawn with replacement. You can read the documentation for this function [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html). Alternatively, you could use the `numpy` function `np.random.randint()` to draw a random number with replacement from the possible index values. You could then use `.iloc` to filter to this subset of rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations: 61788\n",
      "Total rows in palms_bs: 61788\n",
      "Unique rows in palms_bs: 38943\n",
      "90:10 ratio (bootstrap): 23.43\n",
      "90:10 ratio (full data): 23.41\n",
      "Difference: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Your calculation here:\n",
    "\n",
    "n = len(palms)\n",
    "print(f\"Total observations: {n}\")\n",
    "np.random.seed(422)\n",
    "\n",
    "palms_bs = palms.sample(n=n, replace=True)\n",
    "\n",
    "print(f\"Total rows in palms_bs: {len(palms_bs)}\")\n",
    "print(f\"Unique rows in palms_bs: {palms_bs['index'].nunique()}\")\n",
    "\n",
    "ratio_bs = calculate_9010_ratio(palms_bs['imputed_real'])\n",
    "ratio_full = calculate_9010_ratio(palms['imputed_real'])\n",
    "\n",
    "print(f\"90:10 ratio (bootstrap): {ratio_bs:.2f}\")\n",
    "print(f\"90:10 ratio (full data): {ratio_full:.2f}\")\n",
    "print(f\"Difference: {ratio_bs - ratio_full:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation of how the value compares here:_\n",
    "\n",
    "The bootstrap ratio now obtained, `23.43`, is almost identical to the full data one, `23.41`. Such a small difference is due to sampling variation from drawing with replacement, and suggests that our estimate is relatively stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-D: Taking Many Bootstraps {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate your procedure from part 2C above `1000` times, each time saving down your calculation for the 90:10 ratio in the bootstrap sample. Once you have your results from this re-sampling, calculate and report the following:\n",
    "\n",
    "1. What is the mean of your `1000` estimates? What is the standard deviation?\n",
    "2. Create a histogram of these bootstrap estimates and comment on the shape\n",
    "3. Using this simulated data, construct a 95% confidence interval for our estimate of the 90:10 ratio in the full sample\n",
    "\n",
    "Hint: several prior problem sets have done similar simulations. Refer to your code and the solutions as a guide for setting up this problem.\n",
    "\n",
    "Hint: you may wish to recall the `np.random.seed(422)` argument at the top of your cell (but outside the for loop) to make your sampling replicable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of bootstrap estimates: 23.38\n",
      "Standard Deviation of bootstrap estimate: 0.24\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [22.79, 23.75]\n"
     ]
    }
   ],
   "source": [
    "# Your calculations here:\n",
    "np.random.seed(422)\n",
    "n_iter = 1000\n",
    "bootstrap_ratios = np.zeros(n_iter)\n",
    "\n",
    "# Loop\n",
    "for i in range(n_iter):\n",
    "    palms_bs = palms.sample(n=n, replace=True)\n",
    "    bootstrap_ratios[i] = calculate_9010_ratio(palms_bs['imputed_real'])\n",
    "\n",
    "# Mean and SD\n",
    "print(f\"Mean of bootstrap estimates: {bootstrap_ratios.mean():.2f}\")\n",
    "print(f\"Standard Deviation of bootstrap estimate: {bootstrap_ratios.std():.2f}\")\n",
    "\n",
    "# Histogram\n",
    "plt.hist(bootstrap_ratios, bins=30, edgecolor='black')\n",
    "plt.xlabel('90:10 Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bootstrap Distribution of 90:10 Ratio')\n",
    "plt.axvline(ratio_full, color='red', linestyle='--', label='Full sample')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confidence Interval\n",
    "ci_lower = np.percentile(bootstrap_ratios, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_ratios, 97.5)\n",
    "print(f\"95% Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here:_\n",
    "\n",
    "The distribution is right-skewed with most observations concentrated near the mean and a long left tail of less frequent, lower values. This asymmetry suggests some sampling variation, particularly toward lower inequality estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-E: Bootstraps and Inequality Differences By Population Subgroup {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring back to your calculation part 2B, report the difference in the 90:10 ratio between the population groups that exhibited the highest and lowest measures for this value. This is a single estimate from our data on the difference of this measure between these groups. However, like a single estimate for the difference in mean income by group, we would like to understand if this difference could emerge due to random sampling fluctuations.\n",
    "\n",
    "Focusing just on the difference between these two population groups, and following the procedure from parts 2C and 2D above, use a bootstrap approach to generate `1000` different estimates for the difference in 90:10 ratio between these two groups. What is the mean of your simulated values? In what percentage of the simulations was the difference positive? In what percentage of the simulations was the difference negative?\n",
    "\n",
    "Hint: you may wish to reset the random seed with `np.random.seed(407)` as an argument at the top of your cell (but outside the for loop) to make your sampling replicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original difference: 4.80\n",
      "\n",
      "Mean of simulated differences: 5.12\n",
      "Percentage positive: 100.0%\n",
      "Percentage negative: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Your calculation here:\n",
    "\n",
    "group_high = 'African/Black'\n",
    "group_low = 'Coloured'\n",
    "\n",
    "# Original difference\n",
    "ratio_high = calculate_9010_ratio(palms[palms['population group'] == group_high]['imputed_real'])\n",
    "ratio_low = calculate_9010_ratio(palms[palms['population group'] == group_low]['imputed_real'])\n",
    "diff_original = ratio_high - ratio_low\n",
    "print(f\"Original difference: {diff_original:.2f}\")\n",
    "\n",
    "np.random.seed(407)\n",
    "\n",
    "# Bootstrap\n",
    "n_iter = 1000\n",
    "bootstrap_diffs = np.zeros(n_iter)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    palms_bs = palms.sample(n=len(palms), replace=True)    \n",
    "    ratio_high_bs = calculate_9010_ratio(palms_bs[palms_bs['population group'] == group_high]['imputed_real'])\n",
    "    ratio_low_bs = calculate_9010_ratio(palms_bs[palms_bs['population group'] == group_low]['imputed_real'])\n",
    "    bootstrap_diffs[i] = ratio_high_bs - ratio_low_bs\n",
    "\n",
    "print(f\"\\nMean of simulated differences: {bootstrap_diffs.mean():.2f}\")\n",
    "print(f\"Percentage positive: {(bootstrap_diffs > 0).sum() / n_iter * 100:.1f}%\")\n",
    "print(f\"Percentage negative: {(bootstrap_diffs < 0).sum() / n_iter * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here:_\n",
    "\n",
    "The difference between the two groups is statistically significant, and the group `Coloured has a 90:10 ratio constantly lower than the group Africa/Black by 4.80 points`, as we can see in all the iterations from the bootstrap.\n",
    "The difference in inequality between the groups is not due to randomness, and we could assume such a difference exists in the entire population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-F: Conclusions About Inequality {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your bootstrap calculations, does there appear to be a significant difference between the 90:10 ratios across population groups? Summarize your findings in language an intelligent but non-technical policymaker could understand [1-2 paragraphs]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your findings here:_\n",
    "\n",
    "Yes, there is a significant difference between population groups. All groups show high inequality levels:\n",
    "* African/Black: 20.18 (highest)\n",
    "* Coloured: 15.38 (lowest)\n",
    "* White: 19.83\n",
    "* Indian/Asian: 19.83\n",
    "\n",
    "The 4.8-point difference between Coloured and African/Black groups is statistically significant. Our bootstrap analysis—testing 1,000 random samples—confirmed this gap appears 100% of the time, meaning it's a real pattern in the population, not due to chance. This suggests inequality operates differently within each community, which policymakers should consider when designing interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Predicting College Graduation Rates[^1] {-}\n",
    "\n",
    "[^1]: Adapted from data from ISLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question asks you to examine data from a sample of US Colleges to predict graduation rates. The `Colleges.csv` dataset contains information on a number of US colleges and universities, including the following variables:\n",
    "\n",
    "* `Private`: Public/private indicator\n",
    "* `Apps`: Number of applications received\n",
    "* `Accept`: Number of applicants accepted\n",
    "* `Enroll`: Number of new students enrolled\n",
    "* `Top10perc`: New students from top 10 % of high school class\n",
    "* `Top25perc`: New students from top 25 % of high school class\n",
    "* `F.Undergrad`: Number of full-time undergraduates\n",
    "* `P.Undergrad`: Number of part-time undergraduates\n",
    "* `Outstate`: Out-of-state tuition\n",
    "* `Room.Board`: Room and board costs\n",
    "* `Books`: Estimated book costs\n",
    "* `Personal`: Estimated personal spending\n",
    "* `PhD`: Percent of faculty with Ph.D.s\n",
    "* `Terminal`: Percent of faculty with terminal degree\n",
    "* `S.F.Ratio`: Student/faculty ratio\n",
    "* `perc.alumni`: Percent of alumni who donate\n",
    "* `Expend`: Instructional expenditure per student\n",
    "* `Grad.Rate`: Graduation rate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-0: Data Preparation {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data set and save it to a variable named `colleges`. Evaluate the data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names for this data set are not in the easiest format to work with for python. In general you will want to avoid using the period `\".\"` in variable names, as the `\".\"` has special meaning in python which we have seen. Most analysts will want to replace this `\".\"` with an underscore `\"_\"`. Further, many find it easier to work with lower case variable names.\n",
    "\n",
    "There are a number of convenient packages to help with cleaning variable names, especially for the simple modifications described above. One is `pyjanitor` which you can read about [here](https://pyjanitor-devs.github.io/pyjanitor/). If you have never used this package, you may install it with the following code.\n",
    "\n",
    "```python\n",
    "pip install pyjanitor\n",
    "```\n",
    "\n",
    "After installing this code, you may load the package with the usual syntax\n",
    "\n",
    "```python\n",
    "import janitor\n",
    "```\n",
    "\n",
    "After doing this, run the following code (assuming you save the data to a variable `colleges`) and comment on what changes have happened to your data.\n",
    "\n",
    "```python\n",
    "colleges = colleges.clean_names()\n",
    "colleges.head()\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "private",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "apps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "accept",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "enroll",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "top10perc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "top25perc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "f_undergrad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p_undergrad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outstate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "room_board",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "books",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "personal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "phd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "terminal",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "s_f_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "perc_alumni",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "expend",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "grad_rate",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "381e8bd3-3bf1-46a0-a7a6-bd0239f065d7",
       "rows": [
        [
         "0",
         "Abilene Christian University",
         "Yes",
         "1660",
         "1232",
         "721",
         "23",
         "52",
         "2885",
         "537",
         "7440",
         "3300",
         "450",
         "2200",
         "70",
         "78",
         "18.1",
         "12",
         "7041",
         "60"
        ],
        [
         "1",
         "Adelphi University",
         "Yes",
         "2186",
         "1924",
         "512",
         "16",
         "29",
         "2683",
         "1227",
         "12280",
         "6450",
         "750",
         "1500",
         "29",
         "30",
         "12.2",
         "16",
         "10527",
         "56"
        ],
        [
         "2",
         "Adrian College",
         "Yes",
         "1428",
         "1097",
         "336",
         "22",
         "50",
         "1036",
         "99",
         "11250",
         "3750",
         "400",
         "1165",
         "53",
         "66",
         "12.9",
         "30",
         "8735",
         "54"
        ],
        [
         "3",
         "Agnes Scott College",
         "Yes",
         "417",
         "349",
         "137",
         "60",
         "89",
         "510",
         "63",
         "12960",
         "5450",
         "450",
         "875",
         "92",
         "97",
         "7.7",
         "37",
         "19016",
         "59"
        ],
        [
         "4",
         "Alaska Pacific University",
         "Yes",
         "193",
         "146",
         "55",
         "16",
         "44",
         "249",
         "869",
         "7560",
         "4120",
         "800",
         "1500",
         "76",
         "72",
         "11.9",
         "2",
         "10922",
         "15"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>private</th>\n",
       "      <th>apps</th>\n",
       "      <th>accept</th>\n",
       "      <th>enroll</th>\n",
       "      <th>top10perc</th>\n",
       "      <th>top25perc</th>\n",
       "      <th>f_undergrad</th>\n",
       "      <th>p_undergrad</th>\n",
       "      <th>outstate</th>\n",
       "      <th>room_board</th>\n",
       "      <th>books</th>\n",
       "      <th>personal</th>\n",
       "      <th>phd</th>\n",
       "      <th>terminal</th>\n",
       "      <th>s_f_ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>expend</th>\n",
       "      <th>grad_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agnes Scott College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name private  apps  accept  enroll  top10perc  \\\n",
       "0  Abilene Christian University     Yes  1660    1232     721         23   \n",
       "1            Adelphi University     Yes  2186    1924     512         16   \n",
       "2                Adrian College     Yes  1428    1097     336         22   \n",
       "3           Agnes Scott College     Yes   417     349     137         60   \n",
       "4     Alaska Pacific University     Yes   193     146      55         16   \n",
       "\n",
       "   top25perc  f_undergrad  p_undergrad  outstate  room_board  books  personal  \\\n",
       "0         52         2885          537      7440        3300    450      2200   \n",
       "1         29         2683         1227     12280        6450    750      1500   \n",
       "2         50         1036           99     11250        3750    400      1165   \n",
       "3         89          510           63     12960        5450    450       875   \n",
       "4         44          249          869      7560        4120    800      1500   \n",
       "\n",
       "   phd  terminal  s_f_ratio  perc_alumni  expend  grad_rate  \n",
       "0   70        78       18.1           12    7041         60  \n",
       "1   29        30       12.2           16   10527         56  \n",
       "2   53        66       12.9           30    8735         54  \n",
       "3   92        97        7.7           37   19016         59  \n",
       "4   76        72       11.9            2   10922         15  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data set and exploratory / cleaning code\n",
    "import janitor\n",
    "\n",
    "colleges = pd.read_csv('/Users/anialatrofa/Desktop/London School of Economics/Y1/AT/Study Material/PP422/Python/Data/W7 (6) College.csv')\n",
    "\n",
    "colleges = colleges.clean_names()\n",
    "colleges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Comment on changes:_\n",
    "\n",
    "All the column names are in lower cases, and do not have spaces in between words. All dots have been substituted by underscores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-A: Fitting a Model to the Full Data Set {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fit a simple ordinary least squares model to predict the graduation rate for a given college or university in your data set. You may find it helpful to follow the regression formula syntax introduced in Problem Set 5. Recall that you can import the following packages to run basic regressions.\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "```\n",
    "\n",
    "For interpretative regressions like this I tend to prefer using the formula notation contained in `smf.ols()`. The formula notation allows you to specify an outcome (or dependent) variable $y$ in the regression and the various independent variables you would like to regress the outcome variable on. If $x1, x2, x3$ are all independent variables, the general formula notation is to write 'y ~ x1 + x2 + x3'. We provide a string with this formula, along with a provided data set. However, rather than use variables like $y$, we provide the relevant column names from our DataFrame.\n",
    "\n",
    "\n",
    "Run a regression predicting graduation rates as a function of the following variables from the original data set:\n",
    "\n",
    "* `Private`: Public/private indicator\n",
    "* `Top10perc`: New students from top 10 % of high school class\n",
    "* `Top25perc`: New students from top 25 % of high school class\n",
    "* `PhD`: Percent of faculty with Ph.D.s\n",
    "* `Terminal`: Percent of faculty with terminal degree\n",
    "* `S.F.Ratio`: Student/faculty ratio\n",
    "* `perc.alumni`: Percent of alumni who donate\n",
    "* `Expend`: Instructional expenditure per student\n",
    "\n",
    "Briefly summarize the results of your regression. Are all of your variables statistically significant? Are any of your findings contrary to what you would expect given the variable descriptions above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              grad_rate   R-squared:                       0.375\n",
      "Model:                            OLS   Adj. R-squared:                  0.368\n",
      "Method:                 Least Squares   F-statistic:                     57.52\n",
      "Date:                Mon, 17 Nov 2025   Prob (F-statistic):           2.59e-73\n",
      "Time:                        20:22:51   Log-Likelihood:                -3129.1\n",
      "No. Observations:                 777   AIC:                             6276.\n",
      "Df Residuals:                     768   BIC:                             6318.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         29.3382      4.633      6.332      0.000      20.243      38.433\n",
      "private[T.Yes]     8.5083      1.383      6.151      0.000       5.793      11.224\n",
      "top10perc          0.1234      0.072      1.721      0.086      -0.017       0.264\n",
      "top25perc          0.1554      0.058      2.688      0.007       0.042       0.269\n",
      "phd                0.1144      0.060      1.916      0.056      -0.003       0.232\n",
      "terminal          -0.0001      0.065     -0.002      0.998      -0.127       0.127\n",
      "s_f_ratio          0.0955      0.168      0.568      0.570      -0.235       0.426\n",
      "perc_alumni        0.3326      0.049      6.743      0.000       0.236       0.429\n",
      "expend          6.798e-05      0.000      0.456      0.649      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       22.350   Durbin-Watson:                   1.937\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               48.518\n",
      "Skew:                           0.072   Prob(JB):                     2.91e-11\n",
      "Kurtosis:                       4.216   Cond. No.                     1.05e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.05e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Your regression here:\n",
    "\n",
    "reg1b = smf.ols('grad_rate ~ private + top10perc + top25perc + phd + terminal + s_f_ratio + perc_alumni + expend', data=colleges).fit()\n",
    "print(reg1b.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your summary of findings here:_\n",
    "\n",
    "According to the regression I run, not all variables are statistically significant, as the p-value of many is above the 5% threshold/has a t-value below 1.96/contains 0 in the confidence interval:\n",
    "* _top10perc_ and _phd_ would be significant at the 10% α-value, otherwise they are not statistically significant at the 5% confidence level;\n",
    "* _terminal_, _s.f.ratio_, and _expend_ are not statistically significant (at the 1%, 5%, or 10% levels).\n",
    "\n",
    "Only _private_, _top25perc_, and _perc.alumni_ are statistically significant at the 5% level, which means that an increase by one unit in one of those values leads to and increase (or decrease) of a value on average equal to their coefficient, holding all else constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-B: Splitting the Data Into Training and Testing Samples {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of of how well our model may perform on new data, we would like to create a holdout or testing data set to compare our model results to. To create this split of our data we will use functions contained in the sckit-learn library, which also contains many functions for fitting various machine learning and regression models.\n",
    "\n",
    "If needed, you may install this package by running:\n",
    "\n",
    "```python\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "Afterwards, run the following code (assuming your data is saved in a variable `colleges`):\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "colleges_train, colleges_test = train_test_split(colleges, test_size=0.3, random_state=422)\n",
    "```\n",
    "The first line of the above code imports the function `train_test_split` which can be used to randomly divide a data set into two distinct groups.\n",
    "The second line of this function applies this function to the `colleges` data set, using the random seed 422. The results of this split are saved in two new objects: `colleges_train` and `colleges_test`. The `test_size` argument specifies the proportion of observations we would like to have in our holdout or testing sample. A commonly used split is to allocate 70% of the data for training and 30% as a testing set.\n",
    "\n",
    "Run this code and examine the `colleges_train` and `colleges_test` DataFrames. How many observations are in each DataFrame?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 543 observations, \n",
      " Testing set: 234 observations\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "colleges_train, colleges_test = train_test_split(colleges, test_size=0.3, random_state=422)\n",
    "print(f\"Training set: {len(colleges_train)} observations, \\n Testing set: {len(colleges_test)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-C: Fitting a Model to the Training Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the same model you used in part 3-A above to the `colleges_train` data only. Examine the results. How do the coefficient estimates compare to your results when applied to the full data set in part 3-A?\n",
    "\n",
    "Calculate and report the MSE of the model predictions within this training data. Note, to obtain model predictions, the model object you fit has a `get_prediction()` method which will allow you to pass new data as an argument to get predicted values for that new data.\n",
    "\n",
    "As an example, the following code structure can generate predictions from a model:\n",
    "\n",
    "```python\n",
    "mod_example = smf.ols('y ~ x1+ x2', data_original).fit()\n",
    "mod_example_predictions = mod_example.get_predictions(data_new)\n",
    "mod_example_predictions.predicted_mean\n",
    "```\n",
    "Note, you can apply any data to the `.get_predictions()` method, so this can be used to extract fitted values from both the original data or any new data you wish to evaluate.\n",
    "\n",
    "There is also a `fittedvalues` attribute of `mod_example` in the above code which will provide fitted values within this data set itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              grad_rate   R-squared:                       0.363\n",
      "Model:                            OLS   Adj. R-squared:                  0.353\n",
      "Method:                 Least Squares   F-statistic:                     38.01\n",
      "Date:                Mon, 17 Nov 2025   Prob (F-statistic):           8.60e-48\n",
      "Time:                        20:36:17   Log-Likelihood:                -2183.6\n",
      "No. Observations:                 543   AIC:                             4385.\n",
      "Df Residuals:                     534   BIC:                             4424.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         24.8395      5.733      4.332      0.000      13.577      36.102\n",
      "private[T.Yes]     8.9754      1.676      5.355      0.000       5.683      12.268\n",
      "top10perc          0.0947      0.085      1.108      0.268      -0.073       0.263\n",
      "top25perc          0.1707      0.068      2.502      0.013       0.037       0.305\n",
      "phd                0.1271      0.074      1.726      0.085      -0.018       0.272\n",
      "terminal          -0.0384      0.080     -0.478      0.633      -0.196       0.119\n",
      "s_f_ratio          0.3716      0.209      1.775      0.076      -0.040       0.783\n",
      "perc_alumni        0.3443      0.060      5.719      0.000       0.226       0.463\n",
      "expend             0.0002      0.000      1.177      0.240      -0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                       10.628   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.005   Jarque-Bera (JB):               17.816\n",
      "Skew:                          -0.069   Prob(JB):                     0.000135\n",
      "Kurtosis:                       3.877   Cond. No.                     1.08e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.08e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "reg2b = smf.ols('grad_rate ~ private + top10perc + top25perc + phd + terminal + s_f_ratio + perc_alumni + expend', data=colleges_train).fit()\n",
    "print(reg2b.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Training Set: 182.1658\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = reg2b.fittedvalues\n",
    "y_true_train = colleges_train['grad_rate']\n",
    "\n",
    "mse_train = np.mean((y_true_train - y_pred_train)**2)\n",
    "print(f\"MSE Training Set: {mse_train:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your comparison explanation here:_\n",
    "\n",
    "All the variables from before are not statistically significant at the 5% significance level (_top10perc_, _phd_, _terminal_, _s.f.ratio_, and _expend_). The coefficients of the statistically significant ones vary a bit, but they all maintain the same direction of effect (the same sign) on the dependant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-D: Evaluating Model Performance on the Testing Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the model you fit in part 3-C (the model fit to only the training data), predict the estimated graduation rate for each observation in the _testing_ data. Calculate and report the MSE of the model predictions on this testing data. How does this MSE compare to the value calculated in part 3-C above.\n",
    "\n",
    "Recalling the instructions from part 3-C above, the following code structure can generate predictions from a model:\n",
    "\n",
    "```python\n",
    "mod_example = smf.ols('y ~ x1+ x2', data_original).fit()\n",
    "mod_example_predictions = mod_example.get_predictions(data_new)\n",
    "mod_example_predictions.predicted_mean\n",
    "```\n",
    "Note, you can apply any data to the `.get_predictions()` method, so this can be used to extract fitted values from both the original data or any new data you wish to evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              grad_rate   R-squared:                       0.424\n",
      "Model:                            OLS   Adj. R-squared:                  0.403\n",
      "Method:                 Least Squares   F-statistic:                     20.70\n",
      "Date:                Mon, 17 Nov 2025   Prob (F-statistic):           2.24e-23\n",
      "Time:                        20:49:55   Log-Likelihood:                -939.22\n",
      "No. Observations:                 234   AIC:                             1896.\n",
      "Df Residuals:                     225   BIC:                             1928.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         38.7084      7.882      4.911      0.000      23.177      54.240\n",
      "private[T.Yes]     8.1816      2.456      3.332      0.001       3.343      13.021\n",
      "top10perc          0.1927      0.132      1.464      0.145      -0.067       0.452\n",
      "top25perc          0.1148      0.109      1.051      0.294      -0.101       0.330\n",
      "phd                0.0657      0.103      0.636      0.525      -0.138       0.269\n",
      "terminal           0.1125      0.111      1.017      0.310      -0.105       0.330\n",
      "s_f_ratio         -0.4717      0.283     -1.665      0.097      -1.030       0.087\n",
      "perc_alumni        0.2936      0.086      3.419      0.001       0.124       0.463\n",
      "expend            -0.0003      0.000     -1.102      0.272      -0.001       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       23.675   Durbin-Watson:                   1.901\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.855\n",
      "Skew:                           0.450   Prob(JB):                     7.43e-13\n",
      "Kurtosis:                       5.218   Cond. No.                     9.98e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.98e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "MSE Test Set: 179.4019\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "reg3b = smf.ols('grad_rate ~ private + top10perc + top25perc + phd + terminal + s_f_ratio + perc_alumni + expend', data=colleges_test).fit()\n",
    "print(reg3b.summary())\n",
    "\n",
    "y_pred_test = reg3b.fittedvalues\n",
    "y_true_test = colleges_test['grad_rate']\n",
    "\n",
    "mse_test = np.mean((y_true_test - y_pred_test)**2)\n",
    "print(f\"MSE Test Set: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation comparing MSE here:_\n",
    "\n",
    "`Training Set MSE: 182.1658`\n",
    "\n",
    "`Testing Set MSE: 179.4019`\n",
    "\n",
    "The test MSE is slightly lower than the train MSE, indicating that there are similar error rates on both datasets and the model is quite reliable for new observations.\n",
    "There is no overfitting and the model has good predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-E: Removing Non-Significant Variables {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the regression you ran in part 3-C on the training data. This model may have contained several variables that were not found to be statistically significant. Fit a new model where you drop (or omit) all these variables from the regression specification. Use this newly fit model to generate predicted values in the testing data set and report the MSE from this prediction. Did dropping these non-significant variables generate better predictions on the testing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              grad_rate   R-squared:                       0.347\n",
      "Model:                            OLS   Adj. R-squared:                  0.343\n",
      "Method:                 Least Squares   F-statistic:                     95.37\n",
      "Date:                Mon, 17 Nov 2025   Prob (F-statistic):           1.59e-49\n",
      "Time:                        21:17:48   Log-Likelihood:                -2190.4\n",
      "No. Observations:                 543   AIC:                             4389.\n",
      "Df Residuals:                     539   BIC:                             4406.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept         35.0251      1.949     17.972      0.000      31.197      38.853\n",
      "private[T.Yes]     7.2271      1.475      4.901      0.000       4.330      10.124\n",
      "top25perc          0.2878      0.033      8.708      0.000       0.223       0.353\n",
      "perc_alumni        0.3725      0.059      6.344      0.000       0.257       0.488\n",
      "==============================================================================\n",
      "Omnibus:                       11.173   Durbin-Watson:                   1.975\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               17.631\n",
      "Skew:                          -0.127   Prob(JB):                     0.000148\n",
      "Kurtosis:                       3.845   Cond. No.                         224.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "MSE Training Set: 186.7602\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "reg2c = smf.ols('grad_rate ~ private + top25perc + perc_alumni', data=colleges_train).fit()\n",
    "print(reg2c.summary())\n",
    "\n",
    "y_pred_trainc = reg2c.fittedvalues\n",
    "y_true_trainc = colleges_train['grad_rate']\n",
    "\n",
    "mse_trainc = np.mean((y_true_trainc - y_pred_trainc)**2)\n",
    "print(f\"MSE Training Set: {mse_trainc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your explanation here:_\n",
    "\n",
    "The MSE obtained from the new training set (dropping not statistically significant variables) is `186.7602`: it has increased by a few percentage points, compared to the original Train Set MSE.\n",
    "It is a good result, because the model is simpler and the increase is not too high, it is a more robust model, and we haven't lost very important explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/pty.py:95: DeprecationWarning: This process (pid=68005) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook PS6.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 2 image(s).\n",
      "[NbConvertApp] Writing 441089 bytes to PS6.html\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "! jupyter nbconvert --to html PS6.ipynb --no-prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
